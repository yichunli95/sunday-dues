{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11785 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUmOgdr_EVkk",
        "outputId": "cd334a99-39a3-4f47-b3d1-23a05444f537"
      },
      "source": [
        "!wget https://memexqa.cs.cmu.edu/fvta_model_zoo/prepro_v1.1.tgz\n",
        "!gunzip prepro_v1.1.tgz\n",
        "!tar -xvf prepro_v1.1.tar\n",
        "!mv prepro_v1.1/ sunday-dues/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-06 03:26:56--  https://memexqa.cs.cmu.edu/fvta_model_zoo/prepro_v1.1.tgz\n",
            "Resolving memexqa.cs.cmu.edu (memexqa.cs.cmu.edu)... 128.2.220.9\n",
            "Connecting to memexqa.cs.cmu.edu (memexqa.cs.cmu.edu)|128.2.220.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 212511000 (203M) [application/x-gzip]\n",
            "Saving to: ‘prepro_v1.1.tgz’\n",
            "\n",
            "prepro_v1.1.tgz     100%[===================>] 202.67M  69.6MB/s    in 2.9s    \n",
            "\n",
            "2020-12-06 03:27:00 (69.6 MB/s) - ‘prepro_v1.1.tgz’ saved [212511000/212511000]\n",
            "\n",
            "prepro_v1.1/\n",
            "prepro_v1.1/test_data.p\n",
            "prepro_v1.1/train_shared.p\n",
            "prepro_v1.1/test_shared.p\n",
            "prepro_v1.1/train_data.p\n",
            "prepro_v1.1/val_data.p\n",
            "prepro_v1.1/val_shared.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj23x6UIEoyN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import *\n",
        "from torch.utils.data import Dataset\n",
        "import itertools\n",
        "\n",
        "train_data = pd.read_pickle('prepro_v1.1/train_data.p')\n",
        "train_shared = pd.read_pickle('prepro_v1.1/train_shared.p')\n",
        "\n",
        "q_lens = [len(q) for q in train_data['q']]\n",
        "cs_lens = [[len(c) for c in cs] for cs in train_data['cs']]\n",
        "cs_lens = list(itertools.chain(*cs_lens))\n",
        "y_lens = [len(y) for y in train_data['y']]\n",
        "photo_lens = [len(train_shared['albums'][aid]['photo_ids']) for aid in train_shared['albums']]\n",
        "all_photos_lens = [sum(len(train_shared['albums'][aid]['photo_ids']) for aid in aid_list) for aid_list in train_data['aid']]\n",
        "pts_lens = [len(pt) for aid in train_shared['albums'] for pt in train_shared['albums'][aid]['photo_titles']] #number of photos/album\n",
        "when_lens = [len(train_shared['albums'][aid]['when']) for aid in train_shared['albums']]\n",
        "album_title_lens = [len(train_shared['albums'][aid]['title']) for aid in train_shared['albums']]\n",
        "album_desc_lens = [len(train_shared['albums'][aid]['description']) for aid in train_shared['albums']]\n",
        "\n",
        "Q_THRES = int(np.percentile(q_lens, 90)) # 10\n",
        "Y_THRES = int(np.percentile(cs_lens, 90)) # 3, same as np.percentile(y_lens, 90)\n",
        "PTS_THRES = int(np.percentile(pts_lens, 90)) # 8\n",
        "WHEN_THRES = int(np.percentile(when_lens, 90)) # 4\n",
        "PHOTOS_PER_ALBUM = int(np.percentile(photo_lens, 90)) # 10\n",
        "ALBUM_TITLE_THRES = int(np.percentile(album_title_lens, 90)) # 8\n",
        "ALBUM_DESC_THRES = int(np.percentile(album_desc_lens, 50)) # 11\n",
        "\n",
        "def train_collate(batch):\n",
        "    X, Y = zip(*batch)\n",
        "    q_vec = []\n",
        "    cs_vec = []\n",
        "    desc_vec = []\n",
        "    img_feats = []\n",
        "    q_len = []\n",
        "    cs0_len = []\n",
        "    cs1_len = []\n",
        "    cs2_len = []\n",
        "    cs3_len = []\n",
        "    desc_len = []\n",
        "    img_len = []\n",
        "    new_X = {}\n",
        "    for x in X:\n",
        "      q_len.append(x['q_len'])\n",
        "      cs0_len.append(x['cs_lens'][0])\n",
        "      cs1_len.append(x['cs_lens'][1])\n",
        "      cs2_len.append(x['cs_lens'][2])\n",
        "      cs3_len.append(x['cs_lens'][3])\n",
        "      desc_len.append(x['desc_len'])\n",
        "      img_len.append(x['img_len'])\n",
        "      q_vec.append(x['q_vec'])\n",
        "      #x['cs_vec'] expected shape: Y_THRES, 4, 100\n",
        "      cs_vec.append(x['cs_vec'])\n",
        "      desc_vec.append(x['desc_vec'])\n",
        "      img_feats.append(x['img_feats'])\n",
        "\n",
        "    new_X['q_len'] = torch.LongTensor(q_len)\n",
        "    new_X['cs0_lens'] = torch.LongTensor(cs0_len)\n",
        "    new_X['cs1_lens'] = torch.LongTensor(cs1_len)\n",
        "    new_X['cs2_lens'] = torch.LongTensor(cs2_len)\n",
        "    new_X['cs3_lens'] = torch.LongTensor(cs3_len)\n",
        "    new_X['desc_len'] = torch.LongTensor(desc_len)\n",
        "    new_X['img_len'] = torch.LongTensor(img_len)\n",
        "    new_X['q_vec'] = pad_sequence(q_vec, batch_first=False, padding_value=0)  # question \n",
        "    # expected shape: B, Y_THRES, 4, 100\n",
        "    new_X['cs_vec'] = pad_sequence(cs_vec, batch_first=False, padding_value=0) # B, Y_THRES, 4, 100 -> 4 choices T, B, 4, 100\n",
        "    new_X['desc_vec'] = pad_sequence(desc_vec, batch_first=False, padding_value=0)\n",
        "    new_X['img_feats'] = pad_sequence(img_feats, batch_first=False, padding_value=0)\n",
        "\n",
        "    return new_X, torch.LongTensor(Y)\n",
        "\n",
        "class MemexQA_new(Dataset):\n",
        "    def __init__(self, data, shared):\n",
        "        self.data = data\n",
        "        self.shared = shared\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['q'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        returned_item = {}\n",
        "        # self.data keys -> ['q', 'idxs', 'cy', 'ccs', 'qid', 'y', 'aid', 'cq', 'yidx', 'cs']\n",
        "        # self.shared keys -> ['albums', 'pid2feat', 'word2vec', 'charCounter', 'wordCounter']\n",
        "\n",
        "        q = self.data['q'][idx]\n",
        "        # missing glove word-> [0] * 100 embedding\n",
        "        q_vec = torch.FloatTensor(\n",
        "            [self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in\n",
        "             q])\n",
        "        q_vec = q_vec[:Q_THRES]\n",
        "        returned_item['q_vec'] = q_vec  # largest possible shape: Q_THRES * 100\n",
        "        returned_item['q_len'] = q_vec.shape[0] \n",
        "        # choices glove\n",
        "        wrong_cs = self.data['cs'][idx]\n",
        "        correct_c = self.data['y'][idx]\n",
        "        yidx = self.data['yidx'][idx]\n",
        "        if yidx == 0:\n",
        "            cs = [correct_c] + wrong_cs\n",
        "        elif yidx == 1:\n",
        "            cs = wrong_cs[:1] + [correct_c] + wrong_cs[1:]\n",
        "        elif yidx == 2:\n",
        "            cs = wrong_cs[:2] + [correct_c] + wrong_cs[2:]\n",
        "        else:  # yidx == 3\n",
        "            cs = wrong_cs + [correct_c]\n",
        "\n",
        "        cs_vec = [\n",
        "            [self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in\n",
        "             c] for c in cs]\n",
        "        cs_vec = [torch.FloatTensor(c[:Y_THRES]) for c in cs_vec]\n",
        "        cs_lens = [min(Y_THRES, len(each)) for each in cs_vec] #YTHRES\n",
        "        returned_item['cs_vec'] = pad_sequence(cs_vec, batch_first = False)  # [c1, c2, c3, c4]; largest possible shape: 4, Y_THRES, 100 ->  Y_THRES, 4, 100\n",
        "        returned_item['cs_lens'] = cs_lens\n",
        "\n",
        "        # aid: description + title , aid:when , aid : photo_titles + {later ->( photo_captions  + photo tags )}\n",
        "        aid_list = self.data['aid'][idx]\n",
        "        pts_descs = []  # photo-level\n",
        "        pid_features = []  # img features from pre-trained CNN\n",
        "        # for each album\n",
        "        total_cat_len = ALBUM_TITLE_THRES + ALBUM_DESC_THRES + WHEN_THRES + PTS_THRES  # 8 + 11 + 4 + 8 = 31\n",
        "        for aid in aid_list:\n",
        "            # ptags = {for each self.album_itags[aid]}\n",
        "            album = self.shared['albums'][aid]\n",
        "            pts = album['photo_titles']  # all photo titles/aid\n",
        "\n",
        "            # concatenate album description, album title and album when\n",
        "            desc = album['description'][:ALBUM_DESC_THRES] + album['title'][:ALBUM_TITLE_THRES] + album['when'][\n",
        "                                                                                                  :WHEN_THRES]\n",
        "\n",
        "            for pt in pts:\n",
        "                photo_info = desc + pt[:PTS_THRES]\n",
        "                # largest possible shape: total_cat_len, 100\n",
        "                photo_info_vec = [\n",
        "                    self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for\n",
        "                    word in photo_info]\n",
        "                if len(photo_info_vec) < total_cat_len:\n",
        "                    photo_info_vec = photo_info_vec + [[0] * 100 for _ in range(\n",
        "                        total_cat_len - len(photo_info_vec))]  # total_cat_len, 100\n",
        "                pts_descs.append(photo_info_vec)  # total number of photos (varies), total_cat_len, 100\n",
        "\n",
        "            for pid in self.shared['albums'][aid]['photo_ids']:\n",
        "                # img_feats\n",
        "                pid_features.append(self.shared['pid2feat'][pid])  # total number of photos (varies) * 2537\n",
        "\n",
        "        desc_vec = torch.FloatTensor(pts_descs).view(-1,\n",
        "                                                     total_cat_len * 100)  # total number of photos (varies), total_cat_len * 100\n",
        "        returned_item['desc_vec'] = desc_vec\n",
        "        returned_item['desc_len'] = desc_vec.shape[0]\n",
        "        img_feats_vec = torch.FloatTensor(\n",
        "            pid_features)  # total number of photos (varies), 2537; NEWLY CHANGED (no matter what, it will vary; keep consistent with desc_vec)\n",
        "        returned_item['img_feats'] = img_feats_vec\n",
        "        returned_item['img_len'] = img_feats_vec.shape[0]\n",
        "        return returned_item, yidx"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18b-Wc-nFKX-"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import *\n",
        "import pandas as pd\n",
        "\n",
        "# crossEntropyLoss use ignore_index = 0\n",
        "\n",
        "\n",
        "# dims fed into LSTM: seq_len, batch_size, input_size\n",
        "# B, T, F\n",
        "# q_vec -> B, T, 100 (glove embedding)\n",
        "# cs_vec -> B, 4, T = Y_THRES, 100\n",
        "# desc_vec(prev. pt) -> B, T = all_photo_titles_albums * DESC_THRESH, 100\n",
        "# ps_vec -> B, T = num_of_albums * 3, 2537\n",
        "class NewFusionModel(nn.Module):\n",
        "    def __init__(self, q_cs_input_size, desc_input_size, img_input_size, hidden_size, batch_size,\n",
        "                num_layers, device, q_linear_size, img_linear_size, multimodal_out, kernel, stride = 1, rnn_type = 'bilstm'):\n",
        "        super(NewFusionModel, self).__init__()\n",
        "        self.device = device\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "        self.q_cs_input_size = q_cs_input_size   #input_size qvec and cs_vec\n",
        "        self.desc_input_size = desc_input_size\n",
        "        self.img_input_size = img_input_size\n",
        "        self.q_linear_size = q_linear_size # s1\n",
        "        self.img_linear_size = img_linear_size # s2\n",
        "        self.num_directions = 2 if rnn_type == 'bilstm' else 1\n",
        "        self.multimodal_out = multimodal_out\n",
        "        self.kernel = kernel\n",
        "        self.stride = stride\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        if (rnn_type == 'bilstm'):\n",
        "            self.rnn_q = nn.LSTM(q_cs_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = True) # questions\n",
        "            self.rnn_c = nn.LSTM(q_cs_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = True) # choices\n",
        "            self.rnn_desc = nn.LSTM(desc_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = True) # photo titles\n",
        "            self.rnn_ps = nn.LSTM(img_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = True) # image features\n",
        "        else:\n",
        "            self.rnn_q = nn.LSTM(q_cs_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = False)\n",
        "            self.rnn_c = nn.LSTM(q_cs_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = False)\n",
        "            self.rnn_desc = nn.LSTM(desc_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = False)\n",
        "            self.rnn_ps = nn.LSTM(img_input_size, hidden_size, self.num_layers, batch_first = False, bidirectional = False)\n",
        "\n",
        "        self.img_linear = nn.Linear(hidden_size, self.img_linear_size) \n",
        "        self.q_linear = nn.Linear(hidden_size, self.q_linear_size)\n",
        "\n",
        "        self.multimodal_cnn = nn.Conv1d(self.num_directions * self.num_layers, self.multimodal_out, self.kernel, self.stride)\n",
        "        # 2 * hidden_size if not passing in rnn_q hidden output, 3 * hidden_size if passing in \n",
        "        multimodal_cnn_in_size = 2 * hidden_size + self.num_layers * self.num_directions * batch_size * q_linear_size // self.img_linear_size\n",
        "        multimodal_cnn_out_size = (multimodal_cnn_in_size - self.kernel) // self.stride + 1\n",
        "        self.output = nn.Linear(self.multimodal_out * multimodal_cnn_out_size, 1)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        # X is a list of dictionaries: 'q_vec', 'cs_vec', 'desc_vec', 'img_feats'\n",
        "        # BATCH_SIZE = len(X)\n",
        "        # B, T, F\n",
        "        # q_vec -> B, T, 100 (glove embedding)\n",
        "        # cs_vec -> B, 4, T=Y_THRES, 100\n",
        "        # desc_vec(prev. pt) -> B, T=all_photo_titles_albums * 40, 100\n",
        "        # img_feats -> B, T=num_of_albums * 3, 2537\n",
        "\n",
        "\n",
        "        # q_vec = pad_sequence(X['q_vec'], batch_first=False, padding_value=0).to(self.device)  # question \n",
        "        # cs_vec = pad_sequence(X['cs_vec'].permute(0,2,1,3), batch_first = False, padding_value=0).to(self.device) # 4 choices T, B, 4, 100\n",
        "        # desc_vec = pad_sequence(X['desc_vec'], batch_first=False, padding_value=0).to(self.device) \n",
        "        # img_feats = pad_sequence(X['img_feats'], batch_first=False, padding_value=0).to(self.device)\n",
        "        q_vec = X['q_vec']\n",
        "        cs_vec = X['cs_vec']\n",
        "        desc_vec = X['desc_vec']\n",
        "        img_feats = X['img_feats'].to(self.device)\n",
        "        packed_q_vec = pack_padded_sequence(q_vec, X['q_len'], batch_first=False, enforce_sorted = False).to(self.device)\n",
        "        packed_c0_vec = pack_padded_sequence(cs_vec[:, :, 0, :], X['cs0_lens'], batch_first = False, enforce_sorted = False).to(self.device)\n",
        "        packed_c1_vec = pack_padded_sequence(cs_vec[:, :, 1, :], X['cs1_lens'], batch_first = False, enforce_sorted = False).to(self.device)\n",
        "        packed_c2_vec = pack_padded_sequence(cs_vec[:, :, 2, :], X['cs2_lens'], batch_first = False, enforce_sorted = False).to(self.device)\n",
        "        packed_c3_vec = pack_padded_sequence(cs_vec[:, :, 3, :], X['cs3_lens'], batch_first = False, enforce_sorted = False).to(self.device)\n",
        "        packed_pt_vec = pack_padded_sequence(desc_vec, X['desc_len'], batch_first = False, enforce_sorted = False).to(self.device)\n",
        "        #img_feats = img_feats.permute(1,0,2)  # batch_size, seq_len, input_size -> seq_len, batch_size, input_size\n",
        "        \n",
        "        #print(\"packed_c1_vec: \", packed_c1_vec.data.shape)\n",
        "        # hidden dims: num_layers * num_directions, batch_size, hidden_size\n",
        "        _, (lstm_hidden_q, __) = self.rnn_q(packed_q_vec)\n",
        "        _, (lstm_hidden_c0, __) = self.rnn_c(packed_c0_vec)\n",
        "        _, (lstm_hidden_c1, __) = self.rnn_c(packed_c1_vec)\n",
        "        _, (lstm_hidden_c2, __) = self.rnn_c(packed_c2_vec)\n",
        "        _, (lstm_hidden_c3, __) = self.rnn_c(packed_c3_vec)\n",
        "        _, (lstm_hidden_pt, __) = self.rnn_desc(packed_pt_vec)\n",
        "        _, (lstm_hidden_ps, __) = self.rnn_ps(img_feats)\n",
        "        lstm_hidden_cs = [lstm_hidden_c0, lstm_hidden_c1, lstm_hidden_c2, lstm_hidden_c3]\n",
        "        \n",
        "        candidate_weights = self.q_linear(lstm_hidden_q) # output: (num_direction * num_layers, batch_size, self.q_linear_size)\n",
        "        img_feats = self.img_linear(lstm_hidden_ps) # output: (num_direction * num_layers, batch_size, hidden_size)\n",
        "        # dyanmic parameter layer\n",
        "        dynamic_parameter_out = self.num_directions * self.num_layers * self.batch_size * self.q_linear_size // self.img_linear_size\n",
        "        dynamic_parameter_matrix = torch.flatten(candidate_weights)[:self.img_linear_size * dynamic_parameter_out]\n",
        "        dynamic_parameter_matrix = dynamic_parameter_matrix.reshape(self.img_linear_size, dynamic_parameter_out)\n",
        "        q_img_fused = img_feats @ dynamic_parameter_matrix\n",
        "\n",
        "        # multimodal cnn layer\n",
        "        cnn_out_list = []\n",
        "        for i in range(4):\n",
        "            vec = torch.cat((q_img_fused, lstm_hidden_cs[i], lstm_hidden_pt), dim = 2).to(self.device) \n",
        "            vec = vec.permute(1, 0, 2) # batch_size, num_direction * num_layers, 2 * hidden + dynamic_parameter_out\n",
        "            vec = self.multimodal_cnn(vec)\n",
        "            cnn_out_list.append(vec)\n",
        "        for i in range(4):\n",
        "            cnn_out_list[i] = torch.flatten(cnn_out_list[i], start_dim = 1).unsqueeze(1)\n",
        "        classification_input = torch.cat(cnn_out_list, dim = 1) # (batch_size, 4, out_ch * cnn_out)\n",
        "        logits = self.output(classification_input)\n",
        "        return logits.squeeze(2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7v5_ryrFTPd",
        "outputId": "579ba220-fb70-4bf3-8c27-24b967eb0da4"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "import csv\n",
        "\n",
        "# hyperparams\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# optimizer-related\n",
        "MOMENTUM = 1e-2\n",
        "LR = 1e-2\n",
        "LR_STEPSIZE = 3\n",
        "LR_DECAY = 0.85\n",
        "WD = 5e-6\n",
        "\n",
        "\n",
        "\n",
        "def main(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    num_workers = 8 if cuda else 0\n",
        "    print(\"Loading data......\")\n",
        "    start = time.time()\n",
        "    # load data\n",
        "    # train_shared = pd.read_pickle('prepro_v1.1/train_shared.p')\n",
        "    train_shared = pd.read_pickle(train_shared_pth)\n",
        "    # random initial embedding matrix for new words\n",
        "    nonglove_dict = {word: np.random.normal(0, 1, 100) for word in train_shared['wordCounter'] if word not in train_shared['word2vec']}\n",
        "    train_shared['word2vec'].update(nonglove_dict)\n",
        "    \n",
        "    val_shared = pd.read_pickle(val_shared_pth)\n",
        "    val_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in val_shared['wordCounter'] if word not in val_shared['word2vec']}\n",
        "    val_shared['word2vec'].update(val_nonglove_dict)\n",
        "\n",
        "    test_shared = pd.read_pickle(test_shared_pth)\n",
        "    test_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in test_shared['wordCounter'] if word not in test_shared['word2vec']}\n",
        "    test_shared['word2vec'].update(test_nonglove_dict)\n",
        "\n",
        "    # train_data = MemexQA_new(data=pd.read_pickle('prepro_v1.1/train_data.p'), shared=train_shared, info=None)\n",
        "    # valid_data = MemexQA_new(data=pd.read_pickle('prepro_v1.1/val_data.p'), shared=val_shared, info=None)\n",
        "    # test_data = MemexQA_new(data=pd.read_pickle('prepro_v1.1/test_data.p'), shared=test_shared, info=None)\n",
        "    train_data = MemexQA_new(data=pd.read_pickle(train_data_pth), shared=train_shared)\n",
        "    valid_data = MemexQA_new(data=pd.read_pickle(val_data_pth), shared=val_shared)\n",
        "    test_data = MemexQA_new(data=pd.read_pickle(test_data_pth), shared=test_shared)\n",
        "\n",
        "    # random initial embedding matrix for new words\n",
        "    # config.emb_mat = np.array([idx2vec_dict[idx] if idx2vec_dict.has_key(idx) \n",
        "    # else np.random.multivariate_normal(np.zeros(config.word_emb_size), np.eye(config.word_emb_size)) \n",
        "    # for idx in xrange(config.word_vocab_size)],dtype=\"float32\") \n",
        "\n",
        "    train_loader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, **train_loader_args)\n",
        "\n",
        "    valid_loader_args = dict(batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, **valid_loader_args)\n",
        "\n",
        "    test_loader_args = dict(batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, **test_loader_args)\n",
        "    print(f\"Loading data took {time.time() - start:.1f} seconds\")\n",
        "    \n",
        "    # initialize model\n",
        "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "    #model = SimpleLSTMModel(100, 64, hyperparams['batch_size'], 2, device)\n",
        "    # input_size, hidden_size, batch_size, num_layers, device, q_linear_size, img_linear_size, multimodal_out, kernel, stride\n",
        "    \n",
        "    model = NewFusionModel(100, 3100,2537,128, 2, 2, device, 64, 64, 4, 3, 1)\n",
        "    model.to(device)\n",
        "\n",
        "    # setup optim and loss\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #optimizer= optim.SGD(model.parameters(), momentum=hyperparams['momentum'], lr = hyperparams['lr'], weight_decay= hyperparams['weight_decay'])\n",
        "    optimizer= optim.Adam(model.parameters(), lr = LR, weight_decay= WD)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEPSIZE, gamma=LR_DECAY)\n",
        "\n",
        "    # training\n",
        "    print(\"Starting training......\")\n",
        "    for i in range(EPOCHS):\n",
        "        start = time.time()\n",
        "        model.train()\n",
        "        n_correct,n_total = 0, 0\n",
        "        batch_count = 0\n",
        "        t_loss = 0\n",
        "        for j, (batch_data, batch_labels) in enumerate(train_loader):\n",
        "            batch_labels = batch_labels.long().to(device)\n",
        "            if j == len(train_loader) - 1:\n",
        "                break\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_data)\n",
        "            loss = criterion(output, batch_labels)\n",
        "            t_loss += loss.item()\n",
        "            res = torch.argmax(output, 1)\n",
        "            res = res.to(device)\n",
        "            n_correct += (res == batch_labels).sum().item()\n",
        "            n_total += batch_labels.shape[0]\n",
        "            batch_count += 1\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_count % 20 == 19:\n",
        "                print(f\"correct choice:{batch_labels[:3]} , predicted choice: {res[:3]}\")\n",
        "        train_acc = n_correct / n_total\n",
        "        train_loss = t_loss / batch_count\n",
        "        print(f\"TRAIN ===> Epoch {i}, took time {time.time()-start:.1f}s, train accu: {train_acc:.4f}, train loss: {train_loss:.6f}\")\n",
        "        scheduler.step()\n",
        "        \n",
        "        # validate and save model \n",
        "        print(\"Start validation......\")\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            model.eval()            \n",
        "            valid_correct, loss, num_of_batches, num_of_val = 0, 0, 0, 0\n",
        "            # validation for classification\n",
        "            for (vb_data, vb_label) in valid_loader:\n",
        "                vb_label = vb_label.long().to(device)\n",
        "                v_output = model(vb_data)\n",
        "                resm = torch.argmax(v_output, axis=1)\n",
        "                resm = resm.to(device)\n",
        "                correct = (resm == vb_label).sum().item()\n",
        "                valid_correct += correct\n",
        "                loss += criterion(v_output, vb_label).item()\n",
        "                num_of_batches += 1\n",
        "                num_of_val += vb_label.shape[0]\n",
        "                if num_of_batches % 20 == 19:\n",
        "                    print(f\"correct choice:{vb_label[:3]} , predicted choice: {resm[:3]}\")\n",
        "            val_loss = loss / num_of_batches\n",
        "            val_accu = valid_correct / num_of_val\n",
        "        print(f\"VALID ===> Epoch {i}, took time {time.time()-start:.1f}s, valid accu: {val_accu:.4f}, valid loss: {val_loss:.6f}\")\n",
        "        \n",
        "        snapshot_prefix = os.path.join(os.getcwd(), 'snapshot/')\n",
        "        if not os.path.exists(snapshot_prefix):\n",
        "            os.makedirs(snapshot_prefix)\n",
        "        torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict' : scheduler.state_dict(),\n",
        "        }, snapshot_prefix + \"Model_\"+str(i))\n",
        "    \n",
        "    # testing\n",
        "    if not isTrain:\n",
        "        print(\"Start testing......\")\n",
        "        start = time.time()\n",
        "        model.eval()\n",
        "        with torch.no_grad(), open('test_predictions.csv', 'w') as f:\n",
        "            writer = csv.writer(f, delimiter=',')\n",
        "            writer.writerow([\"predict\",\"actual\"])\n",
        "            for (tbatch_data, tbatch_data_labels) in test_loader:\n",
        "                test_out = model(tbatch_data)\n",
        "                predict = torch.argmax(test_out, axis=1)\n",
        "                correct = (predict == tbatch_data_labels).sum().item()\n",
        "                for (pred, actual) in zip(predict, correct):\n",
        "                    writer.writerow([pred, actual])\n",
        "        print(f\"Testing took {time.time()-start:.1f}s\")\n",
        "    print(\"Finished\")\n",
        "                \n",
        "                                                    \n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    main('prepro_v1.1/train_data.p',\n",
        "        'prepro_v1.1/train_shared.p',\n",
        "        'prepro_v1.1/val_data.p',\n",
        "        'prepro_v1.1/val_shared.p',\n",
        "        'prepro_v1.1/test_data.p',\n",
        "        'prepro_v1.1/test_shared.p',\n",
        "        isTrain = True)\n",
        "    # parser = argparse.ArgumentParser(description='Get the train-val-test dataset files')\n",
        "    \n",
        "    # parser.add_argument(\"-td\" , \"--train_data_pth\", help=\"Enter train data path\", type=str)\n",
        "    # parser.add_argument(\"-tds\", \"--train_shared_pth\", help=\"Enter train_shared data path\", type=str)\n",
        "    # parser.add_argument(\"-vd\", \"--val_data_pth\", help=\"Enter val data path\", type=str)\n",
        "    # parser.add_argument(\"-vds\", \"--val_shared_pth\", help=\"Enter val_shared data path\", type=str)\n",
        "    # parser.add_argument(\"-test\", \"--test_data_pth\", help=\"Enter test data path\", type=str)\n",
        "    # parser.add_argument(\"-test_shared\", \"--test_shared_pth\", help=\"Enter test_shared data path\", type=str)\n",
        "    # # parser.add_argument(\"-album\", \"--album_data_pth\", help=\"Enter album_json data path\", type=str)\n",
        "    # parser.add_argument(\"isTrain\", help=\"Set True if model is training\", type=bool)\n",
        "    \n",
        "    # args = parser.parse_args()\n",
        "    \n",
        "    # main(args.train_data_pth,\n",
        "    #     args.train_shared_pth,\n",
        "    #     args.val_data_pth,\n",
        "    #     args.val_shared_pth,\n",
        "    #     args.test_data_pth,\n",
        "    #     args.test_shared_pth,\n",
        "    #     isTrain = args.isTrain)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data......\n",
            "Loading data took 13.3 seconds\n",
            "Starting training......\n",
            "correct choice:tensor([3, 1, 1], device='cuda:0') , predicted choice: tensor([2, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 0], device='cuda:0') , predicted choice: tensor([3, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 0], device='cuda:0') , predicted choice: tensor([3, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 0], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([0, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 3], device='cuda:0') , predicted choice: tensor([0, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 1], device='cuda:0') , predicted choice: tensor([3, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([3, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 0], device='cuda:0') , predicted choice: tensor([0, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([3, 3, 2], device='cuda:0') , predicted choice: tensor([1, 3, 1], device='cuda:0')\n",
            "TRAIN ===> Epoch 0, took time 76.2s, train accu: 0.4070, train loss: 1.249595\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 0, took time 19.1s, valid accu: 0.4208, valid loss: 1.213997\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([0, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 2], device='cuda:0') , predicted choice: tensor([0, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 0], device='cuda:0') , predicted choice: tensor([3, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 1], device='cuda:0') , predicted choice: tensor([1, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 3], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 2], device='cuda:0') , predicted choice: tensor([2, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([2, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([2, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 2], device='cuda:0') , predicted choice: tensor([3, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 1], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "TRAIN ===> Epoch 1, took time 76.2s, train accu: 0.4649, train loss: 1.165924\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([3, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 1, took time 19.0s, valid accu: 0.4437, valid loss: 1.191513\n",
            "correct choice:tensor([2, 3, 2], device='cuda:0') , predicted choice: tensor([2, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 3], device='cuda:0') , predicted choice: tensor([1, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 0], device='cuda:0') , predicted choice: tensor([3, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 3], device='cuda:0') , predicted choice: tensor([3, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 1], device='cuda:0') , predicted choice: tensor([2, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 0], device='cuda:0') , predicted choice: tensor([2, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 2], device='cuda:0') , predicted choice: tensor([0, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 0], device='cuda:0') , predicted choice: tensor([1, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 3, 0], device='cuda:0') , predicted choice: tensor([1, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 2], device='cuda:0') , predicted choice: tensor([0, 1, 2], device='cuda:0')\n",
            "TRAIN ===> Epoch 2, took time 76.7s, train accu: 0.4944, train loss: 1.114655\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 2, took time 19.1s, valid accu: 0.4505, valid loss: 1.217985\n",
            "correct choice:tensor([3, 1, 1], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 3], device='cuda:0') , predicted choice: tensor([0, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 3], device='cuda:0') , predicted choice: tensor([3, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 1, 3], device='cuda:0') , predicted choice: tensor([2, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 0], device='cuda:0') , predicted choice: tensor([0, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 1], device='cuda:0') , predicted choice: tensor([1, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([2, 3, 3], device='cuda:0') , predicted choice: tensor([2, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 0], device='cuda:0') , predicted choice: tensor([0, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 0], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 1], device='cuda:0') , predicted choice: tensor([1, 2, 1], device='cuda:0')\n",
            "TRAIN ===> Epoch 3, took time 75.9s, train accu: 0.5133, train loss: 1.071575\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 3, took time 19.0s, valid accu: 0.4602, valid loss: 1.194448\n",
            "correct choice:tensor([0, 2, 0], device='cuda:0') , predicted choice: tensor([3, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 3], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 3], device='cuda:0') , predicted choice: tensor([0, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 0, 0], device='cuda:0') , predicted choice: tensor([1, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 0], device='cuda:0') , predicted choice: tensor([1, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 0], device='cuda:0') , predicted choice: tensor([3, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 2], device='cuda:0') , predicted choice: tensor([2, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 1], device='cuda:0') , predicted choice: tensor([0, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 1], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 1], device='cuda:0') , predicted choice: tensor([1, 2, 1], device='cuda:0')\n",
            "TRAIN ===> Epoch 4, took time 76.2s, train accu: 0.5325, train loss: 1.039992\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 4, took time 19.1s, valid accu: 0.4564, valid loss: 1.214867\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([0, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 3], device='cuda:0') , predicted choice: tensor([3, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 0], device='cuda:0') , predicted choice: tensor([1, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 2], device='cuda:0') , predicted choice: tensor([2, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 1], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 3], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 1], device='cuda:0') , predicted choice: tensor([1, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 3], device='cuda:0') , predicted choice: tensor([3, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 2], device='cuda:0') , predicted choice: tensor([1, 1, 1], device='cuda:0')\n",
            "TRAIN ===> Epoch 5, took time 76.1s, train accu: 0.5483, train loss: 1.014121\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 5, took time 19.1s, valid accu: 0.4602, valid loss: 1.214788\n",
            "correct choice:tensor([3, 0, 1], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 2], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([3, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 3], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 2], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 2], device='cuda:0') , predicted choice: tensor([1, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 1], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 1], device='cuda:0') , predicted choice: tensor([2, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([3, 2, 3], device='cuda:0')\n",
            "TRAIN ===> Epoch 6, took time 76.0s, train accu: 0.5603, train loss: 0.990037\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 6, took time 19.0s, valid accu: 0.4599, valid loss: 1.229486\n",
            "correct choice:tensor([3, 2, 0], device='cuda:0') , predicted choice: tensor([3, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 0], device='cuda:0') , predicted choice: tensor([0, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 3], device='cuda:0') , predicted choice: tensor([3, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 2], device='cuda:0') , predicted choice: tensor([3, 2, 2], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}