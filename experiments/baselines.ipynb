{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11785 experiments.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHCvJRUbCkRu",
        "outputId": "e6a1c783-a058-4e2a-8ec5-62e74cb25eea"
      },
      "source": [
        "!wget https://memexqa.cs.cmu.edu/fvta_model_zoo/prepro_v1.1.tgz\n",
        "!gunzip prepro_v1.1.tgz\n",
        "!tar -xvf prepro_v1.1.tar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 04:42:49--  https://memexqa.cs.cmu.edu/fvta_model_zoo/prepro_v1.1.tgz\n",
            "Resolving memexqa.cs.cmu.edu (memexqa.cs.cmu.edu)... 128.2.220.9\n",
            "Connecting to memexqa.cs.cmu.edu (memexqa.cs.cmu.edu)|128.2.220.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 212511000 (203M) [application/x-gzip]\n",
            "Saving to: ‘prepro_v1.1.tgz’\n",
            "\n",
            "prepro_v1.1.tgz     100%[===================>] 202.67M  29.0MB/s    in 7.9s    \n",
            "\n",
            "2020-12-09 04:42:57 (25.6 MB/s) - ‘prepro_v1.1.tgz’ saved [212511000/212511000]\n",
            "\n",
            "prepro_v1.1/\n",
            "prepro_v1.1/test_data.p\n",
            "prepro_v1.1/train_shared.p\n",
            "prepro_v1.1/test_shared.p\n",
            "prepro_v1.1/train_data.p\n",
            "prepro_v1.1/val_data.p\n",
            "prepro_v1.1/val_shared.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5EnBklhC2tl"
      },
      "source": [
        "# new_dataset_checked_by_hongyuan.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import *\n",
        "from torch.utils.data import Dataset\n",
        "import itertools\n",
        "\n",
        "train_data = pd.read_pickle('prepro_v1.1/train_data.p')\n",
        "train_shared = pd.read_pickle('prepro_v1.1/train_shared.p')\n",
        "\n",
        "q_lens = [len(q) for q in train_data['q']]\n",
        "cs_lens = [[len(c) for c in cs] for cs in train_data['cs']]\n",
        "cs_lens = list(itertools.chain(*cs_lens))\n",
        "y_lens = [len(y) for y in train_data['y']]\n",
        "photo_lens = [len(train_shared['albums'][aid]['photo_ids']) for aid in train_shared['albums']]\n",
        "all_photos_lens = [sum(len(train_shared['albums'][aid]['photo_ids']) for aid in aid_list) for aid_list in train_data['aid']]\n",
        "pts_lens = [len(pt) for aid in train_shared['albums'] for pt in train_shared['albums'][aid]['photo_titles']]\n",
        "when_lens = [len(train_shared['albums'][aid]['when']) for aid in train_shared['albums']]\n",
        "where_lens = [len(train_shared['albums'][aid]['where']) for aid in train_shared['albums']]\n",
        "album_title_lens = [len(train_shared['albums'][aid]['title']) for aid in train_shared['albums']]\n",
        "album_desc_lens = [len(train_shared['albums'][aid]['description']) for aid in train_shared['albums']]\n",
        "\n",
        "Q_THRES = int(np.percentile(q_lens, 90)) # 10\n",
        "Y_THRES = int(np.percentile(cs_lens, 90)) # 3, same as np.percentile(y_lens, 90)\n",
        "PTS_THRES = int(np.percentile(pts_lens, 90)) # 8\n",
        "WHEN_THRES = int(np.percentile(when_lens, 90)) # 4\n",
        "WHERE_THRES = int(np.percentile(where_lens, 90)) # 5\n",
        "PHOTOS_PER_ALBUM = int(np.percentile(photo_lens, 90)) # 10\n",
        "ALBUM_TITLE_THRES = int(np.percentile(album_title_lens, 90)) # 8\n",
        "ALBUM_DESC_THRES = int(np.percentile(album_desc_lens, 50)) # 11\n",
        "\n",
        "def train_collate(batch):\n",
        "    X, Y = zip(*batch)\n",
        "    q_vec = []\n",
        "    cs_vec = []\n",
        "    desc_vec = []\n",
        "    img_feats = []\n",
        "    q_len = []\n",
        "    cs0_len = []\n",
        "    cs1_len = []\n",
        "    cs2_len = []\n",
        "    cs3_len = []\n",
        "    desc_len = []\n",
        "    img_len = []\n",
        "    qid = []\n",
        "    pid = []\n",
        "    new_X = {}\n",
        "    for x in X:\n",
        "      q_len.append(x['q_len'])\n",
        "      cs0_len.append(x['cs_lens'][0])\n",
        "      cs1_len.append(x['cs_lens'][1])\n",
        "      cs2_len.append(x['cs_lens'][2])\n",
        "      cs3_len.append(x['cs_lens'][3])\n",
        "      desc_len.append(x['desc_len'])\n",
        "      img_len.append(x['img_len'])\n",
        "      q_vec.append(x['q_vec'])\n",
        "      cs_vec.append(x['cs_vec']) # x['cs_vec'] expected shape: <=Y_THRES, 4, 100\n",
        "      desc_vec.append(x['desc_vec'])\n",
        "      img_feats.append(x['img_feats'])\n",
        "      qid.append(x['qid'])\n",
        "      pid.append(x['pids'])\n",
        "\n",
        "    new_X['q_len'] = torch.LongTensor(q_len)\n",
        "    new_X['cs0_lens'] = torch.LongTensor(cs0_len)\n",
        "    new_X['cs1_lens'] = torch.LongTensor(cs1_len)\n",
        "    new_X['cs2_lens'] = torch.LongTensor(cs2_len)\n",
        "    new_X['cs3_lens'] = torch.LongTensor(cs3_len)\n",
        "    new_X['desc_len'] = torch.LongTensor(desc_len)\n",
        "    new_X['img_len'] = torch.LongTensor(img_len)\n",
        "    new_X['q_vec'] = pad_sequence(q_vec, batch_first=False, padding_value=0)  # T, B, 100 \n",
        "    new_X['cs_vec'] = pad_sequence(cs_vec, batch_first=False, padding_value=0)  # B, <=Y_THRES, 4, 100 -> T, B, 4, 100\n",
        "    new_X['desc_vec'] = pad_sequence(desc_vec, batch_first=False, padding_value=0)  # T, B, total_cat_len * 100\n",
        "    new_X['img_feats'] = pad_sequence(img_feats, batch_first=False, padding_value=0)  # T, B, 2537\n",
        "\n",
        "    return new_X, torch.LongTensor(Y), qid, pid\n",
        "\n",
        "class MemexQA_new(Dataset):\n",
        "    def __init__(self, data, shared):\n",
        "        # self.data keys -> ['q', 'idxs', 'cy', 'ccs', 'qid', 'y', 'aid', 'cq', 'yidx', 'cs']\n",
        "        # self.shared keys -> ['albums', 'pid2feat', 'word2vec', 'charCounter', 'wordCounter']\n",
        "        self.data = data\n",
        "        self.shared = shared\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['q'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        returned_item = {}\n",
        "\n",
        "        returned_item['qid'] = self.data['qid'][idx]\n",
        "\n",
        "        q = self.data['q'][idx]\n",
        "        # missing glove word-> [0] * 100 embedding\n",
        "        q_vec = torch.FloatTensor([self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in q])\n",
        "        q_vec = q_vec[:Q_THRES]\n",
        "        returned_item['q_vec'] = q_vec  # largest possible shape: Q_THRES * 100\n",
        "        returned_item['q_len'] = q_vec.shape[0] \n",
        "\n",
        "        wrong_cs = self.data['cs'][idx]\n",
        "        correct_c = self.data['y'][idx]\n",
        "        yidx = self.data['yidx'][idx]\n",
        "        if yidx == 0:\n",
        "            cs = [correct_c] + wrong_cs\n",
        "        elif yidx == 1:\n",
        "            cs = wrong_cs[:1] + [correct_c] + wrong_cs[1:]\n",
        "        elif yidx == 2:\n",
        "            cs = wrong_cs[:2] + [correct_c] + wrong_cs[2:]\n",
        "        else:  # yidx == 3\n",
        "            cs = wrong_cs + [correct_c]\n",
        "        cs_vec = [[self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in c] for c in cs]\n",
        "        cs_vec = [torch.FloatTensor(c[:Y_THRES]) for c in cs_vec]\n",
        "        cs_lens = [min(Y_THRES, len(c)) for c in cs_vec]\n",
        "        returned_item['cs_vec'] = pad_sequence(cs_vec, batch_first = False)  # largest possible shape: 4, Y_THRES, 100 ->  Y_THRES, 4, 100\n",
        "        returned_item['cs_lens'] = cs_lens\n",
        "\n",
        "        # aid: description + title + when + where + photo_titles\n",
        "        aid_list = self.data['aid'][idx]\n",
        "        pts_descs = []  # photo-level text features\n",
        "        pid_features = []  # photo-level img features from pre-trained CNN\n",
        "        pids = []\n",
        "        # for each album\n",
        "        total_cat_len = ALBUM_TITLE_THRES + ALBUM_DESC_THRES + WHEN_THRES + PTS_THRES + WHERE_THRES  # 8 + 11 + 4 + 8 + 5 = 36\n",
        "        for aid in aid_list:\n",
        "            album = self.shared['albums'][aid]\n",
        "            pids.extend(album['photo_ids'])\n",
        "            pts = album['photo_titles']  # all photo titles/aid\n",
        "            # concatenate album description, album title, album when and album where\n",
        "            desc = album['description'][:ALBUM_DESC_THRES] + album['title'][:ALBUM_TITLE_THRES] + album['when'][:WHEN_THRES] + album['where'][:WHERE_THRES]\n",
        "            for pt in pts:\n",
        "                photo_info = desc + pt[:PTS_THRES]\n",
        "                # largest possible shape: total_cat_len, 100\n",
        "                photo_info_vec = [self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in photo_info]\n",
        "                if len(photo_info_vec) < total_cat_len:\n",
        "                    photo_info_vec = photo_info_vec + [[0] * 100 for _ in range(total_cat_len - len(photo_info_vec))]  # total_cat_len, 100\n",
        "                pts_descs.append(photo_info_vec)  # total number of photos (varies), total_cat_len, 100\n",
        "\n",
        "            for pid in self.shared['albums'][aid]['photo_ids']:\n",
        "                # img_feats\n",
        "                pid_features.append(self.shared['pid2feat'][pid])  # total number of photos (varies) * 2537\n",
        "\n",
        "        desc_vec = torch.FloatTensor(pts_descs).view(-1, total_cat_len * 100)  # total number of photos (varies), total_cat_len * 100\n",
        "        returned_item['pids'] = pids\n",
        "        returned_item['desc_vec'] = desc_vec\n",
        "        returned_item['desc_len'] = desc_vec.shape[0]  # total number of photos (varies)\n",
        "        img_feats_vec = torch.FloatTensor(pid_features)  # total number of photos (varies), 2537; NEWLY CHANGED (no matter what, it will vary; keep consistent with desc_vec)\n",
        "        returned_item['img_feats'] = img_feats_vec\n",
        "        returned_item['img_len'] = img_feats_vec.shape[0]  # total number of photos (varies)\n",
        "        return returned_item, yidx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E71TEL6SWs4A"
      },
      "source": [
        "# new_dataset_checked_by_hongyuan.py\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from torch.nn.utils.rnn import *\r\n",
        "from torch.utils.data import Dataset\r\n",
        "import itertools\r\n",
        "\r\n",
        "train_data = pd.read_pickle('prepro_v1.1/train_data.p')\r\n",
        "train_shared = pd.read_pickle('prepro_v1.1/train_shared.p')\r\n",
        "val_data = pd.read_pickle('prepro_v1.1/val_data.p')\r\n",
        "\r\n",
        "q_types = [\"when\", \"what\", \"who\", \"where\", \"how\"]\r\n",
        "qtype2qid = {}\r\n",
        "qtype2qid[\"when\"] = []\r\n",
        "qtype2qid[\"what\"] = []\r\n",
        "qtype2qid[\"who\"] = []\r\n",
        "qtype2qid[\"where\"] = []\r\n",
        "qtype2qid[\"how\"] = []\r\n",
        "\r\n",
        "for i, qid in enumerate(train_data['qid']):\r\n",
        "    if train_data['q'][i][0].lower() == \"when\":\r\n",
        "        qtype2qid[\"when\"].append(qid)\r\n",
        "    elif train_data['q'][i][0].lower() == \"what\":\r\n",
        "        qtype2qid[\"what\"].append(qid)\r\n",
        "    elif train_data['q'][i][0].lower() == \"who\":\r\n",
        "        qtype2qid[\"who\"].append(qid)\r\n",
        "    elif train_data['q'][i][0].lower() == \"where\":\r\n",
        "        qtype2qid[\"where\"].append(qid)\r\n",
        "    elif train_data['q'][i][0].lower() == \"how\":\r\n",
        "        qtype2qid[\"how\"].append(qid)\r\n",
        "\r\n",
        "for i, qid in enumerate(val_data['qid']):\r\n",
        "    if val_data['q'][i][0].lower() == \"when\":\r\n",
        "        qtype2qid[\"when\"].append(qid)\r\n",
        "    elif val_data['q'][i][0].lower() == \"what\":\r\n",
        "        qtype2qid[\"what\"].append(qid)\r\n",
        "    elif val_data['q'][i][0].lower() == \"who\":\r\n",
        "        qtype2qid[\"who\"].append(qid)\r\n",
        "    elif val_data['q'][i][0].lower() == \"where\":\r\n",
        "        qtype2qid[\"where\"].append(qid)\r\n",
        "    elif val_data['q'][i][0].lower() == \"how\":\r\n",
        "        qtype2qid[\"how\"].append(qid)\r\n",
        "\r\n",
        "q_lens = [len(q) for q in train_data['q']]\r\n",
        "cs_lens = [[len(c) for c in cs] for cs in train_data['cs']]\r\n",
        "cs_lens = list(itertools.chain(*cs_lens))\r\n",
        "y_lens = [len(y) for y in train_data['y']]\r\n",
        "photo_lens = [len(train_shared['albums'][aid]['photo_ids']) for aid in train_shared['albums']]\r\n",
        "all_photos_lens = [sum(len(train_shared['albums'][aid]['photo_ids']) for aid in aid_list) for aid_list in train_data['aid']]\r\n",
        "pts_lens = [len(pt) for aid in train_shared['albums'] for pt in train_shared['albums'][aid]['photo_titles']]\r\n",
        "when_lens = [len(train_shared['albums'][aid]['when']) for aid in train_shared['albums']]\r\n",
        "where_lens = [len(train_shared['albums'][aid]['where']) for aid in train_shared['albums']]\r\n",
        "album_title_lens = [len(train_shared['albums'][aid]['title']) for aid in train_shared['albums']]\r\n",
        "album_desc_lens = [len(train_shared['albums'][aid]['description']) for aid in train_shared['albums']]\r\n",
        "\r\n",
        "Q_THRES = int(np.percentile(q_lens, 90)) # 10\r\n",
        "Y_THRES = int(np.percentile(cs_lens, 90)) # 3, same as np.percentile(y_lens, 90)\r\n",
        "PTS_THRES = int(np.percentile(pts_lens, 90)) # 8\r\n",
        "WHEN_THRES = int(np.percentile(when_lens, 90)) # 4\r\n",
        "WHERE_THRES = int(np.percentile(where_lens, 90)) # 5\r\n",
        "PHOTOS_PER_ALBUM = int(np.percentile(photo_lens, 90)) # 10\r\n",
        "ALL_PHOTOS_THRES = max(all_photos_lens) # 72\r\n",
        "ALBUM_TITLE_THRES = int(np.percentile(album_title_lens, 90)) # 8\r\n",
        "ALBUM_DESC_THRES = int(np.percentile(album_desc_lens, 50)) # 11\r\n",
        "\r\n",
        "def train_collate(batch):\r\n",
        "    X, Y = zip(*batch)\r\n",
        "    q_vec = []\r\n",
        "    cs_vec = []\r\n",
        "    desc_vec = []\r\n",
        "    img_feats = []\r\n",
        "    q_len = []\r\n",
        "    cs0_len = []\r\n",
        "    cs1_len = []\r\n",
        "    cs2_len = []\r\n",
        "    cs3_len = []\r\n",
        "    desc_len = []\r\n",
        "    img_len = []\r\n",
        "    qid = []\r\n",
        "    pid = []\r\n",
        "    new_X = {}\r\n",
        "    for x in X:\r\n",
        "      q_len.append(x['q_len'])\r\n",
        "      cs0_len.append(x['cs_lens'][0])\r\n",
        "      cs1_len.append(x['cs_lens'][1])\r\n",
        "      cs2_len.append(x['cs_lens'][2])\r\n",
        "      cs3_len.append(x['cs_lens'][3])\r\n",
        "      desc_len.append(x['desc_len'])\r\n",
        "      img_len.append(x['img_len'])\r\n",
        "      q_vec.append(x['q_vec'])\r\n",
        "      cs_vec.append(x['cs_vec']) # x['cs_vec'] expected shape: <=Y_THRES, 4, 100\r\n",
        "      desc_vec.append(x['desc_vec'])\r\n",
        "      img_feats.append(x['img_feats'])\r\n",
        "      qid.append(x['qid'])\r\n",
        "      pid.append(x['pids'])\r\n",
        "\r\n",
        "    new_X['q_len'] = torch.LongTensor(q_len)\r\n",
        "    new_X['cs0_lens'] = torch.LongTensor(cs0_len)\r\n",
        "    new_X['cs1_lens'] = torch.LongTensor(cs1_len)\r\n",
        "    new_X['cs2_lens'] = torch.LongTensor(cs2_len)\r\n",
        "    new_X['cs3_lens'] = torch.LongTensor(cs3_len)\r\n",
        "    new_X['desc_len'] = torch.LongTensor(desc_len)\r\n",
        "    new_X['img_len'] = torch.LongTensor(img_len)\r\n",
        "    new_X['q_vec'] = pad_sequence(q_vec, batch_first=False, padding_value=0)  # T, B, 100 \r\n",
        "    new_X['cs_vec'] = pad_sequence(cs_vec, batch_first=False, padding_value=0)  # B, <=Y_THRES, 4, 100 -> T, B, 4, 100\r\n",
        "    new_X['desc_vec'] = pad_sequence(desc_vec, batch_first=False, padding_value=0)  # T, B, total_cat_len * 100\r\n",
        "    new_X['img_feats'] = pad_sequence(img_feats, batch_first=False, padding_value=0)  # T, B, 2537\r\n",
        "\r\n",
        "    return new_X, torch.LongTensor(Y), qid, pid\r\n",
        "\r\n",
        "class MemexQA_new(Dataset):\r\n",
        "    def __init__(self, data, shared):\r\n",
        "        # self.data keys -> ['q', 'idxs', 'cy', 'ccs', 'qid', 'y', 'aid', 'cq', 'yidx', 'cs']\r\n",
        "        # self.shared keys -> ['albums', 'pid2feat', 'word2vec', 'charCounter', 'wordCounter']\r\n",
        "        self.data = data\r\n",
        "        self.shared = shared\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data['q'])\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        returned_item = {}\r\n",
        "\r\n",
        "        returned_item['qid'] = self.data['qid'][idx]\r\n",
        "\r\n",
        "        q = self.data['q'][idx]\r\n",
        "        # missing glove word-> [0] * 100 embedding\r\n",
        "        q_vec = torch.FloatTensor([self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in q])\r\n",
        "        q_vec = q_vec[:Q_THRES]\r\n",
        "        returned_item['q_vec'] = q_vec  # largest possible shape: Q_THRES * 100\r\n",
        "        returned_item['q_len'] = q_vec.shape[0] \r\n",
        "\r\n",
        "        wrong_cs = self.data['cs'][idx]\r\n",
        "        correct_c = self.data['y'][idx]\r\n",
        "        yidx = self.data['yidx'][idx]\r\n",
        "        if yidx == 0:\r\n",
        "            cs = [correct_c] + wrong_cs\r\n",
        "        elif yidx == 1:\r\n",
        "            cs = wrong_cs[:1] + [correct_c] + wrong_cs[1:]\r\n",
        "        elif yidx == 2:\r\n",
        "            cs = wrong_cs[:2] + [correct_c] + wrong_cs[2:]\r\n",
        "        else:  # yidx == 3\r\n",
        "            cs = wrong_cs + [correct_c]\r\n",
        "        cs_vec = [[self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in c] for c in cs]\r\n",
        "        cs_vec = [torch.FloatTensor(c[:Y_THRES]) for c in cs_vec]\r\n",
        "        cs_lens = [min(Y_THRES, len(c)) for c in cs_vec]\r\n",
        "        returned_item['cs_vec'] = pad_sequence(cs_vec, batch_first = False)  # largest possible shape: 4, Y_THRES, 100 ->  Y_THRES, 4, 100\r\n",
        "        returned_item['cs_lens'] = cs_lens\r\n",
        "\r\n",
        "        # aid: description + title + when + where + photo_titles\r\n",
        "        aid_list = self.data['aid'][idx]\r\n",
        "        pts_descs = []  # photo-level text features\r\n",
        "        pid_features = []  # photo-level img features from pre-trained CNN\r\n",
        "        pids = []\r\n",
        "        # for each album\r\n",
        "        total_cat_len = ALBUM_TITLE_THRES + ALBUM_DESC_THRES + WHEN_THRES + PTS_THRES + WHERE_THRES  # 8 + 11 + 4 + 8 + 5 = 36\r\n",
        "        for aid in aid_list:\r\n",
        "            album = self.shared['albums'][aid]\r\n",
        "            pids.extend(album['photo_ids'])\r\n",
        "            pts = album['photo_titles']  # all photo titles/aid\r\n",
        "            # concatenate album description, album title, album when and album where\r\n",
        "            desc = album['description'][:ALBUM_DESC_THRES] + album['title'][:ALBUM_TITLE_THRES] + album['when'][:WHEN_THRES] + album['where'][:WHERE_THRES]\r\n",
        "            for pt in pts:\r\n",
        "                photo_info = desc + pt[:PTS_THRES]\r\n",
        "                # largest possible shape: total_cat_len, 100\r\n",
        "                photo_info_vec = [self.shared['word2vec'][word.lower()] if word.lower() in self.shared['word2vec'] else [0] * 100 for word in photo_info]\r\n",
        "                if len(photo_info_vec) < total_cat_len:\r\n",
        "                    photo_info_vec = photo_info_vec + [[0] * 100 for _ in range(total_cat_len - len(photo_info_vec))]  # total_cat_len, 100\r\n",
        "                pts_descs.append(photo_info_vec)  # total number of photos (varies), total_cat_len, 100\r\n",
        "\r\n",
        "            for pid in self.shared['albums'][aid]['photo_ids']:\r\n",
        "                # img_feats\r\n",
        "                pid_features.append(self.shared['pid2feat'][pid])  # total number of photos (varies) * 2537\r\n",
        "\r\n",
        "        desc_vec = torch.FloatTensor(pts_descs).view(-1, total_cat_len * 100)  # total number of photos (varies), total_cat_len * 100\r\n",
        "        returned_item['pids'] = pids\r\n",
        "        returned_item['desc_vec'] = desc_vec\r\n",
        "        returned_item['desc_len'] = desc_vec.shape[0]  # total number of photos (varies)\r\n",
        "        img_feats_vec = torch.FloatTensor(pid_features)  # total number of photos (varies), 2537; NEWLY CHANGED (no matter what, it will vary; keep consistent with desc_vec)\r\n",
        "        returned_item['img_feats'] = img_feats_vec\r\n",
        "        returned_item['img_len'] = img_feats_vec.shape[0]  # total number of photos (varies)\r\n",
        "        return returned_item, yidx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaK-U5E6C64q"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import *\n",
        "import pandas as pd\n",
        "\n",
        "class SimpleLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, batch_size, num_layers, device, rnn_type = 'bilstm'):\n",
        "        super(SimpleLSTMModel, self).__init__()\n",
        "        self.device = device\n",
        "        self.img_feats_reshape = nn.Linear(2537, 100) # T, B, 100\n",
        "        self.desc_reshape = nn.Linear(3600, 100)  # T, B 100\n",
        "        self.flat = nn.Flatten()\n",
        "        if (rnn_type == 'bilstm'):\n",
        "            self.rnn_q = nn.LSTM(input_size, hidden_size, num_layers, batch_first = False, bidirectional = True)\n",
        "            self.rnn_c = nn.LSTM(input_size, hidden_size, num_layers, batch_first = False, bidirectional = True)\n",
        "            self.rnn_pt = nn.LSTM(input_size, hidden_size, num_layers, batch_first = False, bidirectional = True)\n",
        "            self.rnn_ps = nn.LSTM(input_size, hidden_size, num_layers, batch_first = False, bidirectional = True)\n",
        "        self.output = nn.Linear(4 * num_layers * (2 if rnn_type == 'bilstm' else 1) * hidden_size, 1)  # 4 * hidden size is the concatenated dim\n",
        "            \n",
        "\n",
        "    def forward(self, X):\n",
        "        # X is a list of dictionaries: 'q_vec', 'cs_vec', 'pts_vec', 'img_feats'\n",
        "        img_feats = X['img_feats'].to(self.device)\n",
        "        img_feats = self.img_feats_reshape(img_feats)  # T, B, 100\n",
        "        pts_vec = X['desc_vec'].to(self.device)\n",
        "        pts_vec = self.desc_reshape(pts_vec)  # T, B, 100\n",
        "        q_vec = X['q_vec'].to(self.device)  # T, B, 100\n",
        "        cs_vec = X['cs_vec'].to(self.device) # T, B, 4, 100\n",
        "        \n",
        "        packed_q_vec = pack_padded_sequence(q_vec, X['q_len'], enforce_sorted = False)\n",
        "        packed_c1_vec = pack_padded_sequence(cs_vec[:, :, 0, :], X['cs0_lens'], enforce_sorted = False)\n",
        "        packed_c2_vec = pack_padded_sequence(cs_vec[:, :, 1, :], X['cs1_lens'], enforce_sorted = False)\n",
        "        packed_c3_vec = pack_padded_sequence(cs_vec[:, :, 2, :], X['cs2_lens'], enforce_sorted = False)\n",
        "        packed_c4_vec = pack_padded_sequence(cs_vec[:, :, 3, :], X['cs3_lens'], enforce_sorted = False)\n",
        "        packed_pt_vec = pack_padded_sequence(pts_vec, X['desc_len'], enforce_sorted = False)\n",
        "        packed_img_vec = pack_padded_sequence(img_feats, X['img_len'], enforce_sorted=False)\n",
        "        _, (lstm_hidden_q, __) = self.rnn_q(packed_q_vec)  # num_layers * 2, B, hidden_size\n",
        "        _, (lstm_hidden_c1, __) = self.rnn_c(packed_c1_vec)\n",
        "        _, (lstm_hidden_c2, __) = self.rnn_c(packed_c2_vec)\n",
        "        _, (lstm_hidden_c3, __) = self.rnn_c(packed_c3_vec)\n",
        "        _, (lstm_hidden_c4, __) = self.rnn_c(packed_c4_vec)\n",
        "        _, (lstm_hidden_pt, __) = self.rnn_pt(packed_pt_vec)\n",
        "        _, (lstm_hidden_ps, __) = self.rnn_ps(img_feats)\n",
        "        lstm_hidden_cs = [lstm_hidden_c1, lstm_hidden_c2, lstm_hidden_c3, lstm_hidden_c4]\n",
        "      \n",
        "        concat_vec = torch.FloatTensor().to(self.device)\n",
        "        for i in range(4):\n",
        "            vec_to_be_cat = torch.cat((lstm_hidden_q, lstm_hidden_ps, lstm_hidden_cs[i], lstm_hidden_pt), dim = 0) # 4 * num_layers * 2, B, hidden_size\n",
        "            vec_to_be_cat = vec_to_be_cat.permute(1, 0, 2)  # B, 4 * num_layers * 2, hidden_size\n",
        "            vec_to_be_cat = torch.flatten(vec_to_be_cat, 1, 2)  # B, 4 * num_layers * 2 * hidden_size\n",
        "            vec_to_be_cat = torch.unsqueeze(vec_to_be_cat, 1)  # B, 1, 4 * num_layers * 2 * hidden_size\n",
        "            concat_vec = torch.cat((concat_vec, vec_to_be_cat), dim = 1) # B, 4, 4 * num_layers * 2 * hidden_size\n",
        "        out = self.output(concat_vec)  # B, 4, 1\n",
        "        out = out.squeeze(2)  # B, 4\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH4dtq_iJOF9"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import *\n",
        "\n",
        "max_photo_len = max(all_photos_lens)\n",
        "max_q_len = max(q_lens)\n",
        "max_cs_len = max(cs_lens)\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.device = device\n",
        "        self.img_feats_reshape = nn.Linear(2537, 100)\n",
        "        self.desc_reshape = nn.Linear(3600, 100)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.output = nn.Linear((2 * max_photo_len + max_q_len + max_cs_len) * 100, 1)  # TODO\n",
        "\n",
        "    def forward(self, X):\n",
        "        # X is a list of dictionaries: 'q_vec', 'cs_vec', 'pts_vec', 'img_feats'\n",
        "        img_feats = X['img_feats'].to(self.device)\n",
        "        img_feats = self.img_feats_reshape(img_feats) # T, B, 100\n",
        "        img_feats = F.pad(img_feats, [0, 0, 0, 0, 0, max_photo_len - img_feats.shape[0]])\n",
        "        pts_vec = X['desc_vec'].to(self.device)\n",
        "        pts_vec = self.desc_reshape(pts_vec)  # T, B, 100\n",
        "        pts_vec = F.pad(pts_vec, [0, 0, 0, 0, 0, max_photo_len - pts_vec.shape[0]])\n",
        "        q_vec = X['q_vec'].to(self.device)  # T, B, 100\n",
        "        q_vec = F.pad(q_vec, [0, 0, 0, 0, 0, max_q_len - q_vec.shape[0]])\n",
        "        cs_vec = X['cs_vec'].to(self.device) # T, B, 4, 100\n",
        "        cs_vec = F.pad(cs_vec, [0, 0, 0, 0, 0, 0, 0, max_cs_len - cs_vec.shape[0]])\n",
        "        concat_vec = torch.FloatTensor().to(self.device)\n",
        "        for i in range(4):\n",
        "            vec_to_be_cat = torch.unsqueeze(self.flat(torch.cat((q_vec, img_feats, cs_vec[:, :, i, :], pts_vec), dim = 0).permute(1, 0, 2)), 1)  # B, 1, T * 100\n",
        "            concat_vec = torch.cat((concat_vec, vec_to_be_cat), dim = 1)\n",
        "        # len(X), 4, (dataset.Q_THRES + dataset.CS_THRES + dataset.PTS_TOTAL_THRES + dataset.PS_THRES)* 100\n",
        "        out = self.output(concat_vec)  # B, 4, 1\n",
        "        out = out.squeeze(2)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Em7pe51YHYmS",
        "outputId": "f8a535fc-a8dc-4219-ec15-9704afbdd848"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "import csv\n",
        "\n",
        "# hyperparams\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# optimizer-related\n",
        "MOMENTUM = 1e-2\n",
        "LR = 1e-2\n",
        "LR_STEPSIZE = 3\n",
        "LR_DECAY = 0.85\n",
        "WD = 5e-6\n",
        "\n",
        "\n",
        "def main(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    num_workers = 8 if cuda else 0\n",
        "    print(\"Loading data......\")\n",
        "    start = time.time()\n",
        "\n",
        "    train_shared = pd.read_pickle(train_shared_pth)\n",
        "    # random initial embedding matrix for new words\n",
        "    nonglove_dict = {word: np.random.normal(0, 1, 100) for word in train_shared['wordCounter'] if word not in train_shared['word2vec']}\n",
        "    train_shared['word2vec'].update(nonglove_dict)\n",
        "    \n",
        "    val_shared = pd.read_pickle(val_shared_pth)\n",
        "    val_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in val_shared['wordCounter'] if word not in val_shared['word2vec']}\n",
        "    val_shared['word2vec'].update(val_nonglove_dict)\n",
        "\n",
        "    test_shared = pd.read_pickle(test_shared_pth)\n",
        "    test_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in test_shared['wordCounter'] if word not in test_shared['word2vec']}\n",
        "    test_shared['word2vec'].update(test_nonglove_dict)\n",
        "\n",
        "    train_data = MemexQA_new(data=pd.read_pickle(train_data_pth), shared=train_shared)\n",
        "    valid_data = MemexQA_new(data=pd.read_pickle(val_data_pth), shared=val_shared)\n",
        "    test_data = MemexQA_new(data=pd.read_pickle(test_data_pth), shared=test_shared)\n",
        "\n",
        "    train_loader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, **train_loader_args)\n",
        "\n",
        "    valid_loader_args = dict(batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, **valid_loader_args)\n",
        "\n",
        "    test_loader_args = dict(batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, **test_loader_args)\n",
        "    print(f\"Loading data took {time.time() - start:.1f} seconds\")\n",
        "    \n",
        "    # initialize model\n",
        "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "    \n",
        "    model = SimpleLSTMModel(100, 128, 64, 2, device)\n",
        "    model.to(device)\n",
        "\n",
        "    # setup optim and loss\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer= optim.Adam(model.parameters(), lr = LR, weight_decay= WD)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEPSIZE, gamma=LR_DECAY)\n",
        "\n",
        "    # training\n",
        "    print(\"Starting training......\")\n",
        "    for i in range(EPOCHS):\n",
        "        start = time.time()\n",
        "        model.train()\n",
        "        n_correct,n_total = 0, 0\n",
        "        batch_count = 0\n",
        "        t_loss = 0\n",
        "        for j, (batch_data, batch_labels, qid, pid) in enumerate(train_loader):\n",
        "            batch_labels = batch_labels.long().to(device)\n",
        "            if j == len(train_loader) - 1:\n",
        "                break\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_data)\n",
        "            loss = criterion(output, batch_labels)\n",
        "            t_loss += loss.item()\n",
        "            res = torch.argmax(output, 1)\n",
        "            res = res.to(device)\n",
        "            n_correct += (res == batch_labels).sum().item()\n",
        "            n_total += batch_labels.shape[0]\n",
        "            batch_count += 1\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_count % 20 == 19:\n",
        "                print(f\"correct choice:{batch_labels[:3]} , predicted choice: {res[:3]}\")\n",
        "        train_acc = n_correct / n_total\n",
        "        train_loss = t_loss / batch_count\n",
        "        print(f\"TRAIN ===> Epoch {i}, took time {time.time()-start:.1f}s, train accu: {train_acc:.4f}, train loss: {train_loss:.6f}\")\n",
        "        scheduler.step()\n",
        "        \n",
        "        # validate and save model \n",
        "        print(\"Start validation......\")\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            model.eval()            \n",
        "            valid_correct, loss, num_of_batches, num_of_val = 0, 0, 0, 0\n",
        "            # validation for classification\n",
        "            for (vb_data, vb_label, qid, pid) in valid_loader:\n",
        "                vb_label = vb_label.long().to(device)\n",
        "                v_output = model(vb_data)\n",
        "                resm = torch.argmax(v_output, axis=1)\n",
        "                resm = resm.to(device)\n",
        "                correct = (resm == vb_label).sum().item()\n",
        "                valid_correct += correct\n",
        "                loss += criterion(v_output, vb_label).item()\n",
        "                num_of_batches += 1\n",
        "                num_of_val += vb_label.shape[0]\n",
        "                if num_of_batches % 20 == 19:\n",
        "                    print(f\"correct choice:{vb_label[:3]} , predicted choice: {resm[:3]}\")\n",
        "            val_loss = loss / num_of_batches\n",
        "            val_accu = valid_correct / num_of_val\n",
        "        print(f\"VALID ===> Epoch {i}, took time {time.time()-start:.1f}s, valid accu: {val_accu:.4f}, valid loss: {val_loss:.6f}\")\n",
        "        \n",
        "        snapshot_prefix = os.path.join(os.getcwd(), 'snapshot/')\n",
        "        if not os.path.exists(snapshot_prefix):\n",
        "            os.makedirs(snapshot_prefix)\n",
        "        torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict' : scheduler.state_dict(),\n",
        "        }, snapshot_prefix + \"Model_\"+str(i))\n",
        "    \n",
        "    # testing\n",
        "    if not isTrain:\n",
        "        print(\"Start testing......\")\n",
        "        start = time.time()\n",
        "        model.eval()\n",
        "        with torch.no_grad(), open('test_predictions.csv', 'w') as f:\n",
        "            writer = csv.writer(f, delimiter=',')\n",
        "            writer.writerow([\"predict\",\"actual\"])\n",
        "            for (tbatch_data, tbatch_data_labels) in test_loader:\n",
        "                test_out = model(tbatch_data)\n",
        "                predict = torch.argmax(test_out, axis=1)\n",
        "                correct = (predict == tbatch_data_labels).sum().item()\n",
        "                for (pred, actual) in zip(predict, correct):\n",
        "                    writer.writerow([pred, actual])\n",
        "        print(f\"Testing took {time.time()-start:.1f}s\")\n",
        "    print(\"Finished\")\n",
        "                \n",
        "                                                    \n",
        "    \n",
        "main('prepro_v1.1/train_data.p', 'prepro_v1.1/train_shared.p', \n",
        "     'prepro_v1.1/val_data.p', 'prepro_v1.1/val_shared.p', \n",
        "     'prepro_v1.1/test_data.p', 'prepro_v1.1/test_shared.p',\n",
        "     isTrain = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d367da2037d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m      \u001b[0;34m'prepro_v1.1/val_data.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prepro_v1.1/val_shared.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m      \u001b[0;34m'prepro_v1.1/test_data.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prepro_v1.1/test_shared.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m      isTrain = True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d367da2037d4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain_shared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_shared_pth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# random initial embedding matrix for new words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mnonglove_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_shared\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wordCounter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_shared\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2vec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'prepro_v1.1/train_shared.p'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFZ-g86IMpE1",
        "outputId": "7d015caf-f214-4675-db42-d91fa211436f"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "import csv\n",
        "\n",
        "# hyperparams\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# optimizer-related\n",
        "MOMENTUM = 1e-2\n",
        "LR = 1e-2\n",
        "LR_STEPSIZE = 3\n",
        "LR_DECAY = 0.85\n",
        "WD = 5e-6\n",
        "\n",
        "\n",
        "def main(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    num_workers = 8 if cuda else 0\n",
        "    print(\"Loading data......\")\n",
        "    start = time.time()\n",
        "\n",
        "    train_shared = pd.read_pickle(train_shared_pth)\n",
        "    # random initial embedding matrix for new words\n",
        "    nonglove_dict = {word: np.random.normal(0, 1, 100) for word in train_shared['wordCounter'] if word not in train_shared['word2vec']}\n",
        "    train_shared['word2vec'].update(nonglove_dict)\n",
        "    \n",
        "    val_shared = pd.read_pickle(val_shared_pth)\n",
        "    val_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in val_shared['wordCounter'] if word not in val_shared['word2vec']}\n",
        "    val_shared['word2vec'].update(val_nonglove_dict)\n",
        "\n",
        "    test_shared = pd.read_pickle(test_shared_pth)\n",
        "    test_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in test_shared['wordCounter'] if word not in test_shared['word2vec']}\n",
        "    test_shared['word2vec'].update(test_nonglove_dict)\n",
        "\n",
        "    train_data = MemexQA_new(data=pd.read_pickle(train_data_pth), shared=train_shared)\n",
        "    valid_data = MemexQA_new(data=pd.read_pickle(val_data_pth), shared=val_shared)\n",
        "    test_data = MemexQA_new(data=pd.read_pickle(test_data_pth), shared=test_shared)\n",
        "\n",
        "    train_loader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, **train_loader_args)\n",
        "\n",
        "    valid_loader_args = dict(batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, **valid_loader_args)\n",
        "\n",
        "    test_loader_args = dict(batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, **test_loader_args)\n",
        "    print(f\"Loading data took {time.time() - start:.1f} seconds\")\n",
        "    \n",
        "    # initialize model\n",
        "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "    \n",
        "    model = LinearModel(device)\n",
        "    model.to(device)\n",
        "\n",
        "    # setup optim and loss\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer= optim.Adam(model.parameters(), lr = LR, weight_decay= WD)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEPSIZE, gamma=LR_DECAY)\n",
        "\n",
        "    # training\n",
        "    print(\"Starting training......\")\n",
        "    for i in range(EPOCHS):\n",
        "        start = time.time()\n",
        "        model.train()\n",
        "        n_correct,n_total = 0, 0\n",
        "        batch_count = 0\n",
        "        t_loss = 0\n",
        "        for j, (batch_data, batch_labels, qid, pid) in enumerate(train_loader):\n",
        "            batch_labels = batch_labels.long().to(device)\n",
        "            if j == len(train_loader) - 1:\n",
        "                break\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_data)\n",
        "            loss = criterion(output, batch_labels)\n",
        "            t_loss += loss.item()\n",
        "            res = torch.argmax(output, 1)\n",
        "            res = res.to(device)\n",
        "            n_correct += (res == batch_labels).sum().item()\n",
        "            n_total += batch_labels.shape[0]\n",
        "            batch_count += 1\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_count % 20 == 19:\n",
        "                print(f\"correct choice:{batch_labels[:3]} , predicted choice: {res[:3]}\")\n",
        "        train_acc = n_correct / n_total\n",
        "        train_loss = t_loss / batch_count\n",
        "        print(f\"TRAIN ===> Epoch {i}, took time {time.time()-start:.1f}s, train accu: {train_acc:.4f}, train loss: {train_loss:.6f}\")\n",
        "        scheduler.step()\n",
        "        \n",
        "        # validate and save model \n",
        "        print(\"Start validation......\")\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            model.eval()            \n",
        "            valid_correct, loss, num_of_batches, num_of_val = 0, 0, 0, 0\n",
        "            # validation for classification\n",
        "            for (vb_data, vb_label, qid, pid) in valid_loader:\n",
        "                vb_label = vb_label.long().to(device)\n",
        "                v_output = model(vb_data)\n",
        "                resm = torch.argmax(v_output, axis=1)\n",
        "                resm = resm.to(device)\n",
        "                correct = (resm == vb_label).sum().item()\n",
        "                valid_correct += correct\n",
        "                loss += criterion(v_output, vb_label).item()\n",
        "                num_of_batches += 1\n",
        "                num_of_val += vb_label.shape[0]\n",
        "                if num_of_batches % 20 == 19:\n",
        "                    print(f\"correct choice:{vb_label[:3]} , predicted choice: {resm[:3]}\")\n",
        "            val_loss = loss / num_of_batches\n",
        "            val_accu = valid_correct / num_of_val\n",
        "        print(f\"VALID ===> Epoch {i}, took time {time.time()-start:.1f}s, valid accu: {val_accu:.4f}, valid loss: {val_loss:.6f}\")\n",
        "        \n",
        "        snapshot_prefix = os.path.join(os.getcwd(), 'snapshot/')\n",
        "        if not os.path.exists(snapshot_prefix):\n",
        "            os.makedirs(snapshot_prefix)\n",
        "        torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict' : scheduler.state_dict(),\n",
        "        }, snapshot_prefix + \"Model_\"+str(i))\n",
        "    \n",
        "    # testing\n",
        "    if not isTrain:\n",
        "        print(\"Start testing......\")\n",
        "        start = time.time()\n",
        "        model.eval()\n",
        "        with torch.no_grad(), open('test_predictions.csv', 'w') as f:\n",
        "            writer = csv.writer(f, delimiter=',')\n",
        "            writer.writerow([\"predict\",\"actual\"])\n",
        "            for (tbatch_data, tbatch_data_labels) in test_loader:\n",
        "                test_out = model(tbatch_data)\n",
        "                predict = torch.argmax(test_out, axis=1)\n",
        "                correct = (predict == tbatch_data_labels).sum().item()\n",
        "                for (pred, actual) in zip(predict, correct):\n",
        "                    writer.writerow([pred, actual])\n",
        "        print(f\"Testing took {time.time()-start:.1f}s\")\n",
        "    print(\"Finished\")\n",
        "                \n",
        "                                                    \n",
        "    \n",
        "main('prepro_v1.1/train_data.p', 'prepro_v1.1/train_shared.p', \n",
        "     'prepro_v1.1/val_data.p', 'prepro_v1.1/val_shared.p', \n",
        "     'prepro_v1.1/test_data.p', 'prepro_v1.1/test_shared.p',\n",
        "     isTrain = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data......\n",
            "Loading data took 11.7 seconds\n",
            "Starting training......\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([0, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 2], device='cuda:0') , predicted choice: tensor([3, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 1], device='cuda:0') , predicted choice: tensor([2, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 2], device='cuda:0') , predicted choice: tensor([0, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([0, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 2], device='cuda:0') , predicted choice: tensor([3, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 3], device='cuda:0') , predicted choice: tensor([0, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 3], device='cuda:0') , predicted choice: tensor([3, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 2], device='cuda:0') , predicted choice: tensor([2, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 0], device='cuda:0') , predicted choice: tensor([3, 0, 0], device='cuda:0')\n",
            "TRAIN ===> Epoch 0, took time 68.3s, train accu: 0.3579, train loss: 1.330550\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 2, 1], device='cuda:0')\n",
            "VALID ===> Epoch 0, took time 17.5s, valid accu: 0.3861, valid loss: 1.316038\n",
            "correct choice:tensor([2, 2, 2], device='cuda:0') , predicted choice: tensor([0, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 2], device='cuda:0') , predicted choice: tensor([1, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([1, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 2], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 1, 1], device='cuda:0') , predicted choice: tensor([0, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 0], device='cuda:0') , predicted choice: tensor([2, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 2], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 2], device='cuda:0') , predicted choice: tensor([0, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 1], device='cuda:0') , predicted choice: tensor([0, 3, 1], device='cuda:0')\n",
            "TRAIN ===> Epoch 1, took time 67.7s, train accu: 0.3739, train loss: 1.319538\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 1, took time 17.7s, valid accu: 0.3823, valid loss: 1.319041\n",
            "correct choice:tensor([0, 0, 0], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 0], device='cuda:0') , predicted choice: tensor([1, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 3, 1], device='cuda:0') , predicted choice: tensor([3, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([1, 0, 2], device='cuda:0') , predicted choice: tensor([0, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 3], device='cuda:0') , predicted choice: tensor([3, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([2, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 0], device='cuda:0') , predicted choice: tensor([2, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 0], device='cuda:0') , predicted choice: tensor([2, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 0], device='cuda:0') , predicted choice: tensor([0, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 1], device='cuda:0') , predicted choice: tensor([0, 2, 0], device='cuda:0')\n",
            "TRAIN ===> Epoch 2, took time 67.6s, train accu: 0.3788, train loss: 1.318298\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([3, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 2, took time 17.7s, valid accu: 0.3767, valid loss: 1.315069\n",
            "correct choice:tensor([2, 3, 3], device='cuda:0') , predicted choice: tensor([3, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 3], device='cuda:0') , predicted choice: tensor([2, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 2], device='cuda:0') , predicted choice: tensor([2, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 3], device='cuda:0') , predicted choice: tensor([1, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([3, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([0, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 1, 3], device='cuda:0') , predicted choice: tensor([3, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 1], device='cuda:0') , predicted choice: tensor([2, 0, 2], device='cuda:0')\n",
            "TRAIN ===> Epoch 3, took time 67.7s, train accu: 0.3823, train loss: 1.313115\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 3, took time 17.7s, valid accu: 0.3850, valid loss: 1.326055\n",
            "correct choice:tensor([1, 0, 0], device='cuda:0') , predicted choice: tensor([2, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 2], device='cuda:0') , predicted choice: tensor([2, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 1], device='cuda:0') , predicted choice: tensor([0, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 2], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 3, 2], device='cuda:0') , predicted choice: tensor([3, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 0], device='cuda:0') , predicted choice: tensor([0, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 3, 1], device='cuda:0') , predicted choice: tensor([0, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 3], device='cuda:0') , predicted choice: tensor([0, 2, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 0, 3], device='cuda:0') , predicted choice: tensor([1, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 3], device='cuda:0') , predicted choice: tensor([2, 0, 0], device='cuda:0')\n",
            "TRAIN ===> Epoch 4, took time 67.7s, train accu: 0.3849, train loss: 1.312645\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([1, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 1, 1], device='cuda:0')\n",
            "VALID ===> Epoch 4, took time 17.6s, valid accu: 0.3785, valid loss: 1.327762\n",
            "correct choice:tensor([2, 1, 1], device='cuda:0') , predicted choice: tensor([2, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 1, 1], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 0], device='cuda:0') , predicted choice: tensor([1, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 3], device='cuda:0') , predicted choice: tensor([2, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 1], device='cuda:0') , predicted choice: tensor([2, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 3], device='cuda:0') , predicted choice: tensor([1, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 2], device='cuda:0') , predicted choice: tensor([0, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 0], device='cuda:0') , predicted choice: tensor([1, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([2, 3, 1], device='cuda:0') , predicted choice: tensor([0, 0, 0], device='cuda:0')\n",
            "TRAIN ===> Epoch 5, took time 68.0s, train accu: 0.3829, train loss: 1.313911\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 5, took time 17.7s, valid accu: 0.3838, valid loss: 1.313945\n",
            "correct choice:tensor([3, 3, 2], device='cuda:0') , predicted choice: tensor([1, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 3], device='cuda:0') , predicted choice: tensor([3, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 3], device='cuda:0') , predicted choice: tensor([1, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 1], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 2], device='cuda:0') , predicted choice: tensor([0, 1, 0], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 3], device='cuda:0') , predicted choice: tensor([3, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 0], device='cuda:0') , predicted choice: tensor([0, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 3, 3], device='cuda:0') , predicted choice: tensor([2, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 2], device='cuda:0') , predicted choice: tensor([1, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 0, 3], device='cuda:0') , predicted choice: tensor([1, 2, 2], device='cuda:0')\n",
            "TRAIN ===> Epoch 6, took time 67.8s, train accu: 0.3862, train loss: 1.310605\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([3, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 6, took time 17.7s, valid accu: 0.3805, valid loss: 1.318394\n",
            "correct choice:tensor([3, 1, 1], device='cuda:0') , predicted choice: tensor([2, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 2], device='cuda:0') , predicted choice: tensor([3, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 3], device='cuda:0') , predicted choice: tensor([1, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 1, 0], device='cuda:0') , predicted choice: tensor([2, 3, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 0], device='cuda:0') , predicted choice: tensor([0, 0, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 3], device='cuda:0') , predicted choice: tensor([1, 3, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 1, 3], device='cuda:0') , predicted choice: tensor([2, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([3, 3, 1], device='cuda:0') , predicted choice: tensor([3, 3, 1], device='cuda:0')\n",
            "correct choice:tensor([1, 0, 1], device='cuda:0') , predicted choice: tensor([2, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 1], device='cuda:0') , predicted choice: tensor([2, 3, 3], device='cuda:0')\n",
            "TRAIN ===> Epoch 7, took time 67.9s, train accu: 0.3854, train loss: 1.309428\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 2, 1], device='cuda:0')\n",
            "VALID ===> Epoch 7, took time 17.7s, valid accu: 0.3841, valid loss: 1.313910\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([0, 2, 3], device='cuda:0')\n",
            "correct choice:tensor([2, 2, 3], device='cuda:0') , predicted choice: tensor([1, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 2], device='cuda:0') , predicted choice: tensor([3, 1, 1], device='cuda:0')\n",
            "correct choice:tensor([1, 3, 0], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([1, 1, 0], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 1], device='cuda:0') , predicted choice: tensor([2, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([2, 3, 0], device='cuda:0')\n",
            "correct choice:tensor([1, 2, 2], device='cuda:0') , predicted choice: tensor([1, 0, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 0], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 0], device='cuda:0') , predicted choice: tensor([0, 3, 1], device='cuda:0')\n",
            "TRAIN ===> Epoch 8, took time 68.0s, train accu: 0.3855, train loss: 1.309483\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([3, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 1, 1], device='cuda:0')\n",
            "VALID ===> Epoch 8, took time 17.8s, valid accu: 0.3864, valid loss: 1.314459\n",
            "correct choice:tensor([1, 1, 3], device='cuda:0') , predicted choice: tensor([0, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 3, 3], device='cuda:0') , predicted choice: tensor([2, 2, 1], device='cuda:0')\n",
            "correct choice:tensor([3, 0, 0], device='cuda:0') , predicted choice: tensor([3, 1, 3], device='cuda:0')\n",
            "correct choice:tensor([0, 3, 2], device='cuda:0') , predicted choice: tensor([1, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 1, 0], device='cuda:0') , predicted choice: tensor([2, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([3, 2, 0], device='cuda:0') , predicted choice: tensor([2, 0, 0], device='cuda:0')\n",
            "correct choice:tensor([3, 1, 2], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 1], device='cuda:0') , predicted choice: tensor([2, 2, 2], device='cuda:0')\n",
            "correct choice:tensor([2, 0, 1], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 2, 2], device='cuda:0') , predicted choice: tensor([0, 2, 2], device='cuda:0')\n",
            "TRAIN ===> Epoch 9, took time 68.2s, train accu: 0.3871, train loss: 1.306362\n",
            "Start validation......\n",
            "correct choice:tensor([1, 2, 0], device='cuda:0') , predicted choice: tensor([2, 1, 2], device='cuda:0')\n",
            "correct choice:tensor([0, 0, 1], device='cuda:0') , predicted choice: tensor([0, 0, 1], device='cuda:0')\n",
            "VALID ===> Epoch 9, took time 17.8s, valid accu: 0.3794, valid loss: 1.315146\n",
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edxMeG-AW3YG",
        "outputId": "c8c9a596-c755-400d-f1cf-08383ffd85ac"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import time\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import csv\r\n",
        "\r\n",
        "# hyperparams\r\n",
        "EPOCHS = 10\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "# optimizer-related\r\n",
        "MOMENTUM = 1e-2\r\n",
        "LR = 1e-2\r\n",
        "LR_STEPSIZE = 5\r\n",
        "LR_DECAY = 0.85\r\n",
        "WD = 5e-6\r\n",
        "\r\n",
        "def main(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain):\r\n",
        "    cuda = torch.cuda.is_available()\r\n",
        "    num_workers = 8 if cuda else 0\r\n",
        "    print(\"Loading data......\")\r\n",
        "    start = time.time()\r\n",
        "\r\n",
        "    train_shared = pd.read_pickle(train_shared_pth)\r\n",
        "    # random initial embedding matrix for new words\r\n",
        "    nonglove_dict = {word: np.random.normal(0, 1, 100) for word in train_shared['wordCounter'] if word not in train_shared['word2vec']}\r\n",
        "    train_shared['word2vec'].update(nonglove_dict)\r\n",
        "    \r\n",
        "    val_shared = pd.read_pickle(val_shared_pth)\r\n",
        "    val_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in val_shared['wordCounter'] if word not in val_shared['word2vec']}\r\n",
        "    val_shared['word2vec'].update(val_nonglove_dict)\r\n",
        "\r\n",
        "    test_shared = pd.read_pickle(test_shared_pth)\r\n",
        "    test_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in test_shared['wordCounter'] if word not in test_shared['word2vec']}\r\n",
        "    test_shared['word2vec'].update(test_nonglove_dict)\r\n",
        "\r\n",
        "    train_data = MemexQA_new(data=pd.read_pickle(train_data_pth), shared=train_shared)\r\n",
        "    valid_data = MemexQA_new(data=pd.read_pickle(val_data_pth), shared=val_shared)\r\n",
        "    test_data = MemexQA_new(data=pd.read_pickle(test_data_pth), shared=test_shared)\r\n",
        "\r\n",
        "    train_loader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\r\n",
        "        else dict(shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_collate)\r\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, **train_loader_args)\r\n",
        "\r\n",
        "    valid_loader_args = dict(shuffle=False, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\r\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\r\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, **valid_loader_args)\r\n",
        "\r\n",
        "    test_loader_args = dict(shuffle=False, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\r\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)  # TODO: test_collate\r\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, **test_loader_args)\r\n",
        "    print(f\"Loading data took {time.time() - start:.1f} seconds\")\r\n",
        "    \r\n",
        "    # initialize model\r\n",
        "    device = torch.device(\"cuda\" if cuda else \"cpu\")\r\n",
        "    \r\n",
        "    #model = NewFusionModel(100, 3600,2537,128, 2, 2, device, 64, 64, 4, 3, 1)\r\n",
        "    #model = NewLSTMModel(100, 3600, 2537, 128, device)\r\n",
        "    #q_cs_input_size, desc_input_size, img_input_size, hidden_size, linear_size, k1, s1, k2, s2, batch_size, device\r\n",
        "    model = SimpleLSTMModel(100, 128, 64, 2, device)\r\n",
        "    model.to(device)\r\n",
        "\r\n",
        "    # setup optim and loss\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    optimizer= optim.Adam(model.parameters(), lr = LR, weight_decay= WD)\r\n",
        "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEPSIZE, gamma=LR_DECAY)\r\n",
        "\r\n",
        "    # training\r\n",
        "    for i in range(EPOCHS):\r\n",
        "        start = time.time()\r\n",
        "        print(\"Starting training......\")\r\n",
        "        model.train()\r\n",
        "        n_correct, n_total = 0, 0\r\n",
        "        batch_count = 0\r\n",
        "        t_loss = 0\r\n",
        "        q_totals = [0] * 5\r\n",
        "        q_corrects = [0] * 5\r\n",
        "        for j, (batch_data, batch_labels, qids, pids) in enumerate(train_loader):\r\n",
        "            if j == len(train_loader) - 1:\r\n",
        "                break\r\n",
        "            batch_labels = batch_labels.long().to(device)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = model(batch_data)\r\n",
        "            loss = criterion(output, batch_labels)\r\n",
        "            t_loss += loss.item()\r\n",
        "            res = torch.argmax(output, 1)\r\n",
        "            res = res.to(device)\r\n",
        "            for i, qid in enumerate(qids):\r\n",
        "                if qid in qtype2qid[\"when\"]:\r\n",
        "                    q_totals[0] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[0] += 1\r\n",
        "                if qid in qtype2qid[\"what\"]:\r\n",
        "                    q_totals[1] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[1] += 1\r\n",
        "                if qid in qtype2qid[\"who\"]:\r\n",
        "                    q_totals[2] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[2] += 1\r\n",
        "                if qid in qtype2qid[\"where\"]:\r\n",
        "                    q_totals[3] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[3] += 1\r\n",
        "                if qid in qtype2qid[\"how\"]:\r\n",
        "                    q_totals[4] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[4] += 1\r\n",
        "            n_correct += (res == batch_labels).sum().item()\r\n",
        "            n_total += batch_labels.shape[0]\r\n",
        "            batch_count += 1\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            #if batch_count % 20 == 19:\r\n",
        "            #    print(f\"correct choice:{batch_labels[:3]} , predicted choice: {res[:3]}\")\r\n",
        "        train_acc = n_correct / n_total\r\n",
        "        train_loss = t_loss / batch_count\r\n",
        "        print(f\"TRAIN ===> Epoch {i}, took time {time.time()-start:.1f}s, train accu: {train_acc:.4f}, train loss: {train_loss:.6f}\")\r\n",
        "        train_acc_q_type = np.array(q_corrects) /np.array(q_totals)\r\n",
        "        for i in range(5):  # 5 types of questions\r\n",
        "            print(\"TRAIN ACC \", q_types[i], \": \", train_acc_q_type[i])\r\n",
        "        #scheduler.step()\r\n",
        "        \r\n",
        "        # validate and save model \r\n",
        "        print(\"Start validation......\")\r\n",
        "        start = time.time()\r\n",
        "        with torch.no_grad():\r\n",
        "            model.eval()            \r\n",
        "            valid_correct, loss, num_of_batches, num_of_val = 0, 0, 0, 0\r\n",
        "            # validation for classification\r\n",
        "            q_totals = [0] * 5\r\n",
        "            q_corrects = [0] * 5\r\n",
        "            for j, (vb_data, vb_label, qids, pids) in enumerate(valid_loader):\r\n",
        "                if j == len(valid_loader) - 1:\r\n",
        "                    break\r\n",
        "                vb_label = vb_label.long().to(device)\r\n",
        "                v_output = model(vb_data)\r\n",
        "                resm = torch.argmax(v_output, 1)\r\n",
        "                resm = resm.to(device)\r\n",
        "                for i, qid in enumerate(qids):\r\n",
        "                    if qid in qtype2qid[\"when\"]:\r\n",
        "                        q_totals[0] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[0] += 1\r\n",
        "                    if qid in qtype2qid[\"what\"]:\r\n",
        "                        q_totals[1] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[1] += 1\r\n",
        "                    if qid in qtype2qid[\"who\"]:\r\n",
        "                        q_totals[2] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[2] += 1\r\n",
        "                    if qid in qtype2qid[\"where\"]:\r\n",
        "                        q_totals[3] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[3] += 1\r\n",
        "                    if qid in qtype2qid[\"how\"]:\r\n",
        "                        q_totals[4] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[4] += 1\r\n",
        "                correct = (resm == vb_label).sum().item()\r\n",
        "                valid_correct += correct\r\n",
        "                loss += criterion(v_output, vb_label).item()\r\n",
        "                num_of_batches += 1\r\n",
        "                num_of_val += vb_label.shape[0]\r\n",
        "                #if num_of_batches % 20 == 19:\r\n",
        "                #    print(f\"correct choice:{vb_label[:3]} , predicted choice: {resm[:3]}\")\r\n",
        "            val_loss = loss / num_of_batches\r\n",
        "            val_accu = valid_correct / num_of_val\r\n",
        "        print(f\"VALID ===> Epoch {i}, took time {time.time()-start:.1f}s, valid accu: {val_accu:.4f}, valid loss: {val_loss:.6f}\")\r\n",
        "        train_acc_q_type = np.array(q_corrects) /np.array(q_totals)\r\n",
        "        for i in range(5):  # 5 types of questions\r\n",
        "            print(\"VALID ACC \", q_types[i], \": \", train_acc_q_type[i])\r\n",
        "        \r\n",
        "        snapshot_prefix = os.path.join(os.getcwd(), 'snapshot/')\r\n",
        "        if not os.path.exists(snapshot_prefix):\r\n",
        "            os.makedirs(snapshot_prefix)\r\n",
        "        torch.save({\r\n",
        "                    'model_state_dict': model.state_dict(),\r\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "                    #'scheduler_state_dict' : scheduler.state_dict(),\r\n",
        "        }, snapshot_prefix + \"Model_\"+str(i))\r\n",
        "    \r\n",
        "    # testing\r\n",
        "    if not isTrain:\r\n",
        "        print(\"Start testing......\")\r\n",
        "        start = time.time()\r\n",
        "        model.eval()\r\n",
        "        with torch.no_grad(), open('test_predictions.csv', 'w') as f:\r\n",
        "            writer = csv.writer(f, delimiter=',')\r\n",
        "            writer.writerow([\"predict\",\"actual\"])\r\n",
        "            for (tbatch_data, tbatch_data_labels) in test_loader:\r\n",
        "                test_out = model(tbatch_data)\r\n",
        "                predict = torch.argmax(test_out, axis=1)\r\n",
        "                correct = (predict == tbatch_data_labels).sum().item()\r\n",
        "                for (pred, actual) in zip(predict, correct):\r\n",
        "                    writer.writerow([pred, actual])\r\n",
        "        print(f\"Testing took {time.time()-start:.1f}s\")\r\n",
        "    print(\"Finished\")\r\n",
        "                \r\n",
        "                                                    \r\n",
        "    \r\n",
        "main('prepro_v1.1/train_data.p', 'prepro_v1.1/train_shared.p', \r\n",
        "     'prepro_v1.1/val_data.p', 'prepro_v1.1/val_shared.p', \r\n",
        "     'prepro_v1.1/test_data.p', 'prepro_v1.1/test_shared.p',\r\n",
        "     isTrain = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data......\n",
            "Loading data took 13.2 seconds\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 79.7s, train accu: 0.4062, train loss: 1.254618\n",
            "TRAIN ACC  when :  0.3131625441696113\n",
            "TRAIN ACC  what :  0.454025974025974\n",
            "TRAIN ACC  who :  0.23964497041420119\n",
            "TRAIN ACC  where :  0.2547215496368039\n",
            "TRAIN ACC  how :  0.7040586245772266\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 19.8s, valid accu: 0.4292, valid loss: 1.218276\n",
            "VALID ACC  when :  0.3538205980066445\n",
            "VALID ACC  what :  0.4919071076706545\n",
            "VALID ACC  who :  0.25935828877005346\n",
            "VALID ACC  where :  0.25678119349005424\n",
            "VALID ACC  how :  0.6900452488687783\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 79.8s, train accu: 0.4626, train loss: 1.167015\n",
            "TRAIN ACC  when :  0.31746031746031744\n",
            "TRAIN ACC  what :  0.5585991678224688\n",
            "TRAIN ACC  who :  0.26934435912581217\n",
            "TRAIN ACC  where :  0.28889966068831796\n",
            "TRAIN ACC  how :  0.7224099099099099\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 19.9s, valid accu: 0.4552, valid loss: 1.198136\n",
            "VALID ACC  when :  0.3588039867109635\n",
            "VALID ACC  what :  0.5376495425756509\n",
            "VALID ACC  who :  0.26737967914438504\n",
            "VALID ACC  where :  0.26763110307414106\n",
            "VALID ACC  how :  0.7149321266968326\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 79.9s, train accu: 0.4930, train loss: 1.116389\n",
            "TRAIN ACC  when :  0.32245258050286724\n",
            "TRAIN ACC  what :  0.6097137901127494\n",
            "TRAIN ACC  who :  0.3030124040165387\n",
            "TRAIN ACC  where :  0.30959302325581395\n",
            "TRAIN ACC  how :  0.7256885890949972\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 20.0s, valid accu: 0.4584, valid loss: 1.187286\n",
            "VALID ACC  when :  0.34551495016611294\n",
            "VALID ACC  what :  0.558057705840957\n",
            "VALID ACC  who :  0.25668449197860965\n",
            "VALID ACC  where :  0.2603978300180832\n",
            "VALID ACC  how :  0.7104072398190046\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 79.8s, train accu: 0.5136, train loss: 1.080170\n",
            "TRAIN ACC  when :  0.3258476442095993\n",
            "TRAIN ACC  what :  0.6453347207769684\n",
            "TRAIN ACC  who :  0.3071005917159763\n",
            "TRAIN ACC  where :  0.3315585672797677\n",
            "TRAIN ACC  how :  0.7340845070422535\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 19.9s, valid accu: 0.4575, valid loss: 1.192792\n",
            "VALID ACC  when :  0.34053156146179403\n",
            "VALID ACC  what :  0.5672061928219564\n",
            "VALID ACC  who :  0.24598930481283424\n",
            "VALID ACC  where :  0.24773960216998192\n",
            "VALID ACC  how :  0.7058823529411765\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 80.3s, train accu: 0.5284, train loss: 1.048651\n",
            "TRAIN ACC  when :  0.31954225352112675\n",
            "TRAIN ACC  what :  0.6802496965493324\n",
            "TRAIN ACC  who :  0.3228858663512714\n",
            "TRAIN ACC  where :  0.3213592233009709\n",
            "TRAIN ACC  how :  0.7384701912260967\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 20.0s, valid accu: 0.4581, valid loss: 1.209979\n",
            "VALID ACC  when :  0.34053156146179403\n",
            "VALID ACC  what :  0.5608726249120338\n",
            "VALID ACC  who :  0.2700534759358289\n",
            "VALID ACC  where :  0.2603978300180832\n",
            "VALID ACC  how :  0.6945701357466063\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 79.6s, train accu: 0.5393, train loss: 1.028632\n",
            "TRAIN ACC  when :  0.32259488084730803\n",
            "TRAIN ACC  what :  0.692894280762565\n",
            "TRAIN ACC  who :  0.32701421800947866\n",
            "TRAIN ACC  where :  0.34849951597289447\n",
            "TRAIN ACC  how :  0.7401574803149606\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 19.9s, valid accu: 0.4567, valid loss: 1.227156\n",
            "VALID ACC  when :  0.3372093023255814\n",
            "VALID ACC  what :  0.5700211118930331\n",
            "VALID ACC  who :  0.25935828877005346\n",
            "VALID ACC  where :  0.22965641952983726\n",
            "VALID ACC  how :  0.7058823529411765\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 80.1s, train accu: 0.5488, train loss: 1.008922\n",
            "TRAIN ACC  when :  0.3249669749009247\n",
            "TRAIN ACC  what :  0.7091571279916753\n",
            "TRAIN ACC  who :  0.3398230088495575\n",
            "TRAIN ACC  where :  0.35336888027144936\n",
            "TRAIN ACC  how :  0.7411167512690355\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 20.2s, valid accu: 0.4508, valid loss: 1.241324\n",
            "VALID ACC  when :  0.3388704318936877\n",
            "VALID ACC  what :  0.5573539760731879\n",
            "VALID ACC  who :  0.2192513368983957\n",
            "VALID ACC  where :  0.2549728752260398\n",
            "VALID ACC  how :  0.7013574660633484\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 80.2s, train accu: 0.5561, train loss: 0.992510\n",
            "TRAIN ACC  when :  0.32365875109938436\n",
            "TRAIN ACC  what :  0.7174856745962841\n",
            "TRAIN ACC  who :  0.36991150442477877\n",
            "TRAIN ACC  where :  0.35672797676669893\n",
            "TRAIN ACC  how :  0.7401352874859075\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 20.0s, valid accu: 0.4525, valid loss: 1.240396\n",
            "VALID ACC  when :  0.3438538205980066\n",
            "VALID ACC  what :  0.573539760731879\n",
            "VALID ACC  who :  0.20588235294117646\n",
            "VALID ACC  where :  0.22603978300180833\n",
            "VALID ACC  how :  0.7036199095022625\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 80.5s, train accu: 0.5601, train loss: 0.984468\n",
            "TRAIN ACC  when :  0.3243719700308506\n",
            "TRAIN ACC  what :  0.7260748959778086\n",
            "TRAIN ACC  who :  0.3578199052132701\n",
            "TRAIN ACC  where :  0.36266924564796904\n",
            "TRAIN ACC  how :  0.744225352112676\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 20.3s, valid accu: 0.4629, valid loss: 1.238159\n",
            "VALID ACC  when :  0.3338870431893688\n",
            "VALID ACC  what :  0.5939479239971851\n",
            "VALID ACC  who :  0.23529411764705882\n",
            "VALID ACC  where :  0.2314647377938517\n",
            "VALID ACC  how :  0.6990950226244343\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 80.5s, train accu: 0.5668, train loss: 0.971251\n",
            "TRAIN ACC  when :  0.3236331569664903\n",
            "TRAIN ACC  what :  0.731622746185853\n",
            "TRAIN ACC  who :  0.365361803084223\n",
            "TRAIN ACC  where :  0.38461538461538464\n",
            "TRAIN ACC  how :  0.7453625632377741\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 20.1s, valid accu: 0.4587, valid loss: 1.243175\n",
            "VALID ACC  when :  0.313953488372093\n",
            "VALID ACC  what :  0.5812807881773399\n",
            "VALID ACC  who :  0.23529411764705882\n",
            "VALID ACC  where :  0.24954792043399637\n",
            "VALID ACC  how :  0.7126696832579186\n",
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u36ceqR0zjBo",
        "outputId": "6fe17dcd-e5d9-4a9f-cbb5-0df3b2722eaa"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import time\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import csv\r\n",
        "\r\n",
        "# hyperparams\r\n",
        "EPOCHS = 10\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "# optimizer-related\r\n",
        "MOMENTUM = 1e-2\r\n",
        "LR = 1e-2\r\n",
        "LR_STEPSIZE = 5\r\n",
        "LR_DECAY = 0.85\r\n",
        "WD = 5e-6\r\n",
        "\r\n",
        "def main(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain):\r\n",
        "    cuda = torch.cuda.is_available()\r\n",
        "    num_workers = 8 if cuda else 0\r\n",
        "    print(\"Loading data......\")\r\n",
        "    start = time.time()\r\n",
        "\r\n",
        "    train_shared = pd.read_pickle(train_shared_pth)\r\n",
        "    # random initial embedding matrix for new words\r\n",
        "    nonglove_dict = {word: np.random.normal(0, 1, 100) for word in train_shared['wordCounter'] if word not in train_shared['word2vec']}\r\n",
        "    train_shared['word2vec'].update(nonglove_dict)\r\n",
        "    \r\n",
        "    val_shared = pd.read_pickle(val_shared_pth)\r\n",
        "    val_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in val_shared['wordCounter'] if word not in val_shared['word2vec']}\r\n",
        "    val_shared['word2vec'].update(val_nonglove_dict)\r\n",
        "\r\n",
        "    test_shared = pd.read_pickle(test_shared_pth)\r\n",
        "    test_nonglove_dict = {word: np.random.normal(0, 1, 100) for word in test_shared['wordCounter'] if word not in test_shared['word2vec']}\r\n",
        "    test_shared['word2vec'].update(test_nonglove_dict)\r\n",
        "\r\n",
        "    train_data = MemexQA_new(data=pd.read_pickle(train_data_pth), shared=train_shared)\r\n",
        "    valid_data = MemexQA_new(data=pd.read_pickle(val_data_pth), shared=val_shared)\r\n",
        "    test_data = MemexQA_new(data=pd.read_pickle(test_data_pth), shared=test_shared)\r\n",
        "\r\n",
        "    train_loader_args = dict(shuffle=True, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\r\n",
        "        else dict(shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_collate)\r\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, **train_loader_args)\r\n",
        "\r\n",
        "    valid_loader_args = dict(shuffle=False, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\r\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)\r\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, **valid_loader_args)\r\n",
        "\r\n",
        "    test_loader_args = dict(shuffle=False, batch_size=BATCH_SIZE, num_workers=num_workers, pin_memory=True, collate_fn=train_collate) if cuda\\\r\n",
        "        else dict(shuffle=False, batch_size=BATCH_SIZE, collate_fn=train_collate)  # TODO: test_collate\r\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, **test_loader_args)\r\n",
        "    print(f\"Loading data took {time.time() - start:.1f} seconds\")\r\n",
        "    \r\n",
        "    # initialize model\r\n",
        "    device = torch.device(\"cuda\" if cuda else \"cpu\")\r\n",
        "    \r\n",
        "    #model = NewFusionModel(100, 3600,2537,128, 2, 2, device, 64, 64, 4, 3, 1)\r\n",
        "    #model = NewLSTMModel(100, 3600, 2537, 128, device)\r\n",
        "    #q_cs_input_size, desc_input_size, img_input_size, hidden_size, linear_size, k1, s1, k2, s2, batch_size, device\r\n",
        "    #model = SimpleLSTMModel(100, 128, 64, 2, device)\r\n",
        "    model = LinearModel(device)\r\n",
        "    model.to(device)\r\n",
        "\r\n",
        "    # setup optim and loss\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    optimizer= optim.Adam(model.parameters(), lr = LR, weight_decay= WD)\r\n",
        "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEPSIZE, gamma=LR_DECAY)\r\n",
        "\r\n",
        "    # training\r\n",
        "    for i in range(EPOCHS):\r\n",
        "        start = time.time()\r\n",
        "        print(\"Starting training......\")\r\n",
        "        model.train()\r\n",
        "        n_correct, n_total = 0, 0\r\n",
        "        batch_count = 0\r\n",
        "        t_loss = 0\r\n",
        "        q_totals = [0] * 5\r\n",
        "        q_corrects = [0] * 5\r\n",
        "        for j, (batch_data, batch_labels, qids, pids) in enumerate(train_loader):\r\n",
        "            if j == len(train_loader) - 1:\r\n",
        "                break\r\n",
        "            batch_labels = batch_labels.long().to(device)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = model(batch_data)\r\n",
        "            loss = criterion(output, batch_labels)\r\n",
        "            t_loss += loss.item()\r\n",
        "            res = torch.argmax(output, 1)\r\n",
        "            res = res.to(device)\r\n",
        "            for i, qid in enumerate(qids):\r\n",
        "                if qid in qtype2qid[\"when\"]:\r\n",
        "                    q_totals[0] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[0] += 1\r\n",
        "                if qid in qtype2qid[\"what\"]:\r\n",
        "                    q_totals[1] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[1] += 1\r\n",
        "                if qid in qtype2qid[\"who\"]:\r\n",
        "                    q_totals[2] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[2] += 1\r\n",
        "                if qid in qtype2qid[\"where\"]:\r\n",
        "                    q_totals[3] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[3] += 1\r\n",
        "                if qid in qtype2qid[\"how\"]:\r\n",
        "                    q_totals[4] += 1\r\n",
        "                    if batch_labels[i] == res[i]:\r\n",
        "                        q_corrects[4] += 1\r\n",
        "            n_correct += (res == batch_labels).sum().item()\r\n",
        "            n_total += batch_labels.shape[0]\r\n",
        "            batch_count += 1\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            #if batch_count % 20 == 19:\r\n",
        "            #    print(f\"correct choice:{batch_labels[:3]} , predicted choice: {res[:3]}\")\r\n",
        "        train_acc = n_correct / n_total\r\n",
        "        train_loss = t_loss / batch_count\r\n",
        "        print(f\"TRAIN ===> Epoch {i}, took time {time.time()-start:.1f}s, train accu: {train_acc:.4f}, train loss: {train_loss:.6f}\")\r\n",
        "        train_acc_q_type = np.array(q_corrects) /np.array(q_totals)\r\n",
        "        for i in range(5):  # 5 types of questions\r\n",
        "            print(\"TRAIN ACC \", q_types[i], \": \", train_acc_q_type[i])\r\n",
        "        #scheduler.step()\r\n",
        "        \r\n",
        "        # validate and save model \r\n",
        "        print(\"Start validation......\")\r\n",
        "        start = time.time()\r\n",
        "        with torch.no_grad():\r\n",
        "            model.eval()            \r\n",
        "            valid_correct, loss, num_of_batches, num_of_val = 0, 0, 0, 0\r\n",
        "            # validation for classification\r\n",
        "            q_totals = [0] * 5\r\n",
        "            q_corrects = [0] * 5\r\n",
        "            for j, (vb_data, vb_label, qids, pids) in enumerate(valid_loader):\r\n",
        "                if j == len(valid_loader) - 1:\r\n",
        "                    break\r\n",
        "                vb_label = vb_label.long().to(device)\r\n",
        "                v_output = model(vb_data)\r\n",
        "                resm = torch.argmax(v_output, 1)\r\n",
        "                resm = resm.to(device)\r\n",
        "                for i, qid in enumerate(qids):\r\n",
        "                    if qid in qtype2qid[\"when\"]:\r\n",
        "                        q_totals[0] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[0] += 1\r\n",
        "                    if qid in qtype2qid[\"what\"]:\r\n",
        "                        q_totals[1] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[1] += 1\r\n",
        "                    if qid in qtype2qid[\"who\"]:\r\n",
        "                        q_totals[2] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[2] += 1\r\n",
        "                    if qid in qtype2qid[\"where\"]:\r\n",
        "                        q_totals[3] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[3] += 1\r\n",
        "                    if qid in qtype2qid[\"how\"]:\r\n",
        "                        q_totals[4] += 1\r\n",
        "                        if vb_label[i] == resm[i]:\r\n",
        "                            q_corrects[4] += 1\r\n",
        "                correct = (resm == vb_label).sum().item()\r\n",
        "                valid_correct += correct\r\n",
        "                loss += criterion(v_output, vb_label).item()\r\n",
        "                num_of_batches += 1\r\n",
        "                num_of_val += vb_label.shape[0]\r\n",
        "                #if num_of_batches % 20 == 19:\r\n",
        "                #    print(f\"correct choice:{vb_label[:3]} , predicted choice: {resm[:3]}\")\r\n",
        "            val_loss = loss / num_of_batches\r\n",
        "            val_accu = valid_correct / num_of_val\r\n",
        "        print(f\"VALID ===> Epoch {i}, took time {time.time()-start:.1f}s, valid accu: {val_accu:.4f}, valid loss: {val_loss:.6f}\")\r\n",
        "        train_acc_q_type = np.array(q_corrects) /np.array(q_totals)\r\n",
        "        for i in range(5):  # 5 types of questions\r\n",
        "            print(\"VALID ACC \", q_types[i], \": \", train_acc_q_type[i])\r\n",
        "        \r\n",
        "        snapshot_prefix = os.path.join(os.getcwd(), 'snapshot/')\r\n",
        "        if not os.path.exists(snapshot_prefix):\r\n",
        "            os.makedirs(snapshot_prefix)\r\n",
        "        torch.save({\r\n",
        "                    'model_state_dict': model.state_dict(),\r\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "                    #'scheduler_state_dict' : scheduler.state_dict(),\r\n",
        "        }, snapshot_prefix + \"Model_\"+str(i))\r\n",
        "    \r\n",
        "    # testing\r\n",
        "    if not isTrain:\r\n",
        "        print(\"Start testing......\")\r\n",
        "        start = time.time()\r\n",
        "        model.eval()\r\n",
        "        with torch.no_grad(), open('test_predictions.csv', 'w') as f:\r\n",
        "            writer = csv.writer(f, delimiter=',')\r\n",
        "            writer.writerow([\"predict\",\"actual\"])\r\n",
        "            for (tbatch_data, tbatch_data_labels) in test_loader:\r\n",
        "                test_out = model(tbatch_data)\r\n",
        "                predict = torch.argmax(test_out, axis=1)\r\n",
        "                correct = (predict == tbatch_data_labels).sum().item()\r\n",
        "                for (pred, actual) in zip(predict, correct):\r\n",
        "                    writer.writerow([pred, actual])\r\n",
        "        print(f\"Testing took {time.time()-start:.1f}s\")\r\n",
        "    print(\"Finished\")\r\n",
        "                \r\n",
        "                                                    \r\n",
        "    \r\n",
        "main('prepro_v1.1/train_data.p', 'prepro_v1.1/train_shared.p', \r\n",
        "     'prepro_v1.1/val_data.p', 'prepro_v1.1/val_shared.p', \r\n",
        "     'prepro_v1.1/test_data.p', 'prepro_v1.1/test_shared.p',\r\n",
        "     isTrain = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data......\n",
            "Loading data took 11.6 seconds\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 69.8s, train accu: 0.3676, train loss: 1.328521\n",
            "TRAIN ACC  when :  0.3224669603524229\n",
            "TRAIN ACC  what :  0.38326679395938207\n",
            "TRAIN ACC  who :  0.23244837758112094\n",
            "TRAIN ACC  where :  0.25823643410852715\n",
            "TRAIN ACC  how :  0.6299212598425197\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 18.4s, valid accu: 0.3762, valid loss: 1.329135\n",
            "VALID ACC  when :  0.3554817275747508\n",
            "VALID ACC  what :  0.39901477832512317\n",
            "VALID ACC  who :  0.25668449197860965\n",
            "VALID ACC  where :  0.20976491862567812\n",
            "VALID ACC  how :  0.6402714932126696\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 69.7s, train accu: 0.3809, train loss: 1.316311\n",
            "TRAIN ACC  when :  0.31748128577719065\n",
            "TRAIN ACC  what :  0.4040561622464899\n",
            "TRAIN ACC  who :  0.25339633786178384\n",
            "TRAIN ACC  where :  0.2513343037360505\n",
            "TRAIN ACC  how :  0.6589627959413754\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 18.2s, valid accu: 0.3738, valid loss: 1.321007\n",
            "VALID ACC  when :  0.33222591362126247\n",
            "VALID ACC  what :  0.40534834623504573\n",
            "VALID ACC  who :  0.2620320855614973\n",
            "VALID ACC  where :  0.20976491862567812\n",
            "VALID ACC  how :  0.6289592760180995\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 69.9s, train accu: 0.3842, train loss: 1.316198\n",
            "TRAIN ACC  when :  0.3123070136744596\n",
            "TRAIN ACC  what :  0.40803602355386215\n",
            "TRAIN ACC  who :  0.24258600237247924\n",
            "TRAIN ACC  where :  0.26692456479690524\n",
            "TRAIN ACC  how :  0.6700507614213198\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 18.3s, valid accu: 0.3771, valid loss: 1.331095\n",
            "VALID ACC  when :  0.3388704318936877\n",
            "VALID ACC  what :  0.41731175228712175\n",
            "VALID ACC  who :  0.24064171122994651\n",
            "VALID ACC  where :  0.21880650994575046\n",
            "VALID ACC  how :  0.6131221719457014\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 69.6s, train accu: 0.3811, train loss: 1.318184\n",
            "TRAIN ACC  when :  0.32171226831421007\n",
            "TRAIN ACC  what :  0.4032928942807626\n",
            "TRAIN ACC  who :  0.23668639053254437\n",
            "TRAIN ACC  where :  0.2612699951526903\n",
            "TRAIN ACC  how :  0.6610455311973018\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 18.2s, valid accu: 0.3665, valid loss: 1.327091\n",
            "VALID ACC  when :  0.3372093023255814\n",
            "VALID ACC  what :  0.3856439127375088\n",
            "VALID ACC  who :  0.2700534759358289\n",
            "VALID ACC  where :  0.19529837251356238\n",
            "VALID ACC  how :  0.6402714932126696\n",
            "Starting training......\n",
            "TRAIN ===> Epoch 63, took time 70.2s, train accu: 0.3831, train loss: 1.317507\n",
            "TRAIN ACC  when :  0.3159752868490733\n",
            "TRAIN ACC  what :  0.4022888850355471\n",
            "TRAIN ACC  who :  0.24985233313644417\n",
            "TRAIN ACC  where :  0.2677012609117362\n",
            "TRAIN ACC  how :  0.6668539325842696\n",
            "Start validation......\n",
            "VALID ===> Epoch 63, took time 18.2s, valid accu: 0.3777, valid loss: 1.323138\n",
            "VALID ACC  when :  0.3521594684385382\n",
            "VALID ACC  what :  0.40253342716396906\n",
            "VALID ACC  who :  0.25133689839572193\n",
            "VALID ACC  where :  0.2224231464737794\n",
            "VALID ACC  how :  0.6334841628959276\n",
            "Starting training......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-14:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n",
            "    return reduction.recv_handle(conn)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n",
            "    return recvfds(s, 1)[0]\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 153, in recvfds\n",
            "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-61fdc35fe92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m      \u001b[0;34m'prepro_v1.1/val_data.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prepro_v1.1/val_shared.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m      \u001b[0;34m'prepro_v1.1/test_data.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prepro_v1.1/test_shared.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m      isTrain = True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-61fdc35fe92e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_data_pth, train_shared_pth, val_data_pth, val_shared_pth, test_data_pth, test_shared_pth, isTrain)\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0mq_corrects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mqid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqtype2qid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"what\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                     \u001b[0mq_totals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}